# 227 docs tagged with "crawl"
(source: https://docs.atlan.com/tags/crawl)



## Add descriptions
(source: https://docs.atlan.com/tags/crawl)

You can add descriptions to your assets in Atlan, including tables, views, and individual columns. You can even add a description in the form of a [README](/product/integrations). Doing so will enrich your data asset with the relevant contextual information.



## Add options
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You must be an admin user in Atlan to create options for custom metadata properties.



## Automate data profiling
(source: https://docs.atlan.com/tags/crawl)

âAvailable via the Data Quality Studio package



## Can I connect to any source with an ODBC/JDBC driver?
(source: https://docs.atlan.com/tags/crawl)

A number of Atlan's [supported connectors](/product/connections/references/connectors-and-capabilities) use a JDBC- or REST API-based approach for metadata extraction.Â If you are attempting to connect to a source with no native integration, [contact Atlan support](/support/submit-request) to share more details about your use case.



## Can I turn off sample data preview for the entire organization?
(source: https://docs.atlan.com/tags/crawl)

Atlan recommends that you turn off sample data preview at a connection level. For example, you can configure the [Snowflake crawler](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake) to prevent users from previewing any Snowflake data.



## Crawl Aiven Kafka
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Aiven Kafka permissions](/apps/connectors/messaging/aiven-kafka/how-tos/set-up-aiven-kafka), you can establish a connection between Atlan and Aiven Kafka.



## Crawl Amazon Athena
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from Amazon Athena, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl Amazon DynamoDB
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Amazon DynamoDB permissions](/apps/connectors/database/amazon-dynamodb/how-tos/set-up-amazon-dynamodb), you can establish a connection between Atlan and Amazon DynamoDB.



## Crawl Amazon MSK
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from Amazon MSK, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl Amazon QuickSight
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Amazon QuickSight permissions](/apps/connectors/business-intelligence/amazon-quicksight/how-tos/set-up-amazon-quicksight),.



## Crawl Amazon Redshift
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [Amazon Redshift access permissions](/apps/connectors/data-warehouses/amazon-redshift/how-tos/set-up-amazon-redshift), you can establish a connection between Atlan and Amazon Redshift.



## Crawl Apache Kafka
(source: https://docs.atlan.com/tags/crawl)

Learn about crawl apache kafka.



## Crawl AWS Glue
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [AWS Glue access permissions](/apps/connectors/etl-tools/aws-glue/how-tos/set-up-aws-glue), you can establish a connection between Atlan and AWS Glue.



## Crawl BigID
(source: https://docs.atlan.com/tags/crawl)

Configure and run the Atlan BigID workflow to crawl metadata from BigID.



## Crawl Confluent Kafka
(source: https://docs.atlan.com/tags/crawl)

Learn about crawl confluent kafka.



## Crawl Confluent Schema Registry
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Confluent Schema Registry access permissions](/apps/connectors/schema/confluent-schema-registry/how-tos/set-up-confluent-schema-registry), you can establish a connection between Atlan and Confluent Schema Registry.



## Crawl CrateDB
(source: https://docs.atlan.com/tags/crawl)

Configure and run the CrateDB crawler to extract metadata from your database



## Crawl Databricks
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from your Databricks instance, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl DataStax Enterprise
(source: https://docs.atlan.com/tags/crawl)

Crawl DataStax Enterprise



## Crawl dbt
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured a dbt Cloud service token](/apps/connectors/etl-tools/dbt/how-tos/set-up-dbt-cloud) or [uploaded your dbt Core project files to S3](/apps/connectors/etl-tools/dbt/how-tos/set-up-dbt-core), you can crawl dbt metadata into Atlan.



## Crawl Domo
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Domo permissions](/apps/connectors/business-intelligence/domo/how-tos/set-up-domo), you can establish a connection between Atlan and Domo.



## Crawl Fivetran
(source: https://docs.atlan.com/tags/crawl)

Learn about crawl fivetran.



## Crawl GCS assets
(source: https://docs.atlan.com/tags/crawl)

Configure and run the GCS crawler to catalog your GCP GCS buckets and objects in Atlan.



## Crawl Google BigQuery
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [Google BigQuery user permissions](/apps/connectors/data-warehouses/google-bigquery/how-tos/set-up-google-bigquery), you can establish a connection between Atlan and Google BigQuery.



## Crawl Hive
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from Hive, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl IBM Cognos Analytics
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the IBM Cognos Analytics permissions](/apps/connectors/business-intelligence/ibm-cognos-analytics/how-tos/set-up-ibm-cognos-analytics), you can establish a connection between Atlan and IBM Cognos Analytics.



## Crawl Informatica CDI assets
(source: https://docs.atlan.com/tags/crawl)

Configure and run the crawler to discover and catalog your Informatica CDI assets



## Crawl Looker
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [Looker user permissions](/apps/connectors/business-intelligence/looker/how-tos/set-up-looker), you can establish a connection between Atlan and Looker.



## Crawl Matillion
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Matillion user permissions](/apps/connectors/etl-tools/matillion/how-tos/set-up-matillion), you can establish a connection between Atlan and Matillion.



## Crawl Metabase
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Metabase user permissions](/apps/connectors/business-intelligence/metabase/how-tos/set-up-metabase), you can establish a connection between Atlan and Metabase.



## Crawl Microsoft Azure Cosmos DB
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Microsoft Azure Cosmos DB permissions](/apps/connectors/database/microsoft-azure-cosmos-db/how-tos/set-up-microsoft-azure-cosmos-db), you can establish a connection between Atlan and Microsoft Azure Cosmos DB.



## Crawl Microsoft Azure Data Factory
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Microsoft Azure Data Factory permissions](/apps/connectors/etl-tools/microsoft-azure-data-factory/how-tos/set-up-microsoft-.



## Crawl Microsoft Azure Event Hubs
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Microsoft Azure Event Hubs permissions](/apps/connectors/messaging/microsoft-azure-event-hubs/how-tos/set-up-microsoft-azure-event-hubs), you can establish a connection between Atlan and Microsoft Azure Event Hubs.



## Crawl Microsoft Azure Synapse Analytics
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Microsoft Azure Synapse Analytics permissions](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics), you can establish a connection between Atlan and Microsoft Azure Synapse Analytics.



## Crawl Microsoft Power BI
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [Microsoft Power BI user permissions](/apps/connectors/business-intelligence/microsoft-power-bi/how-tos/set-up-microsoft-power-bi), you can establish a connection between Atlan and Microsoft Power BI.



## Crawl Microsoft SQL Server
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [Microsoft SQL Server user permissions](/apps/connectors/database/microsoft-sql-server/how-tos/set-up-microsoft-sql-server),.



## Crawl MicroStrategy
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the MicroStrategy permissions](/apps/connectors/business-intelligence/microstrategy/how-tos/set-up-microstrategy), you can establish a connection between Atlan and MicroStrategy.



## Crawl Mode
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Mode user permissions](/apps/connectors/business-intelligence/mode/how-tos/set-up-mode), you can establish a connection between Atlan and Mode.



## Crawl MongoDB
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the MongoDB permissions](/apps/connectors/database/mongodb/how-tos/set-up-mongodb), you can establish a connection between Atlan and MongoDB.



## Crawl Monte Carlo
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Monte Carlo permissions](/apps/connectors/observability/monte-carlo/how-tos/set-up-monte-carlo), you can establish a connection between Atlan and Monte Carlo.



## Crawl MySQL
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from MySQL, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl on-premises databases
(source: https://docs.atlan.com/tags/crawl)

Once you have [set up the metadata-extractor tool](/apps/connectors/database/on-premises-databases/how-tos/set-up-on-premises-database-access), you can extract metadata from your on-premises databases using the following steps.



## Crawl on-premises Databricks
(source: https://docs.atlan.com/tags/crawl)

Once you have [set up the databricks-extractor tool](/apps/connectors/database/on-premises-databases/references/supported-connections-for-on-premises-databases), you can extract metadata from your on-premises Databricks instances by completing the following steps.



## Crawl on-premises IBM Cognos Analytics
(source: https://docs.atlan.com/tags/crawl)

Once you have [set up the cognos-extractor tool](/apps/connectors/business-intelligence/ibm-cognos-analytics/how-tos/set-up-on-premises-ibm-cognos-analytics-access), you can extract metadata from your on-premises IBM Cognos Analytics instances by completing the following steps.



## Crawl on-premises Kafka
(source: https://docs.atlan.com/tags/crawl)

Once you have [set up the kafka-extractor tool](/apps/connectors/messaging/on-premises-event-buses/how-tos/set-up-on-premises-kafka-access), you can extract metadata from your on-premises Kafka instances by completing the following steps.



## Crawl on-premises Looker
(source: https://docs.atlan.com/tags/crawl)

Once you have [set up the looker-extractor tool](/apps/connectors/business-intelligence/looker/how-tos/set-up-on-premises-looker-access), you can extract metadata from your on-premises Looker instances using the following steps.



## Crawl on-premises Tableau
(source: https://docs.atlan.com/tags/crawl)

Once you have [set up the tableau-extractor tool](/apps/connectors/business-intelligence/tableau/how-tos/set-up-on-premises-tableau-access), you can extract metadata from your on-premises Tableau instances by completing the following steps.



## Crawl on-premises ThoughtSpot
(source: https://docs.atlan.com/tags/crawl)

Once you have [set up the thoughtspot-extractor tool](/apps/connectors/business-intelligence/thoughtspot/how-tos/set-up-on-premises-thoughtspot-access),.



## Crawl Oracle
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [Oracle user permissions](/apps/connectors/database/oracle/how-tos/set-up-oracle#create-user-in-oracle), you can establish a connection between Atlan and Oracle.



## Crawl PostgreSQL
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from PostgreSQL, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl PrestoSQL
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [PrestoSQL user permissions](/apps/connectors/database/prestosql/how-tos/set-up-prestosql), you can establish a connection between Atlan and PrestoSQL.



## Crawl Qlik Sense Cloud
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Qlik Sense Cloud permissions](/apps/connectors/business-intelligence/qlik-sense-cloud/how-tos/set-up-qlik-sense-cloud), you can establish a connection between Atlan and Qlik Sense Cloud.



## Crawl Qlik Sense Enterprise on Windows
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Qlik Sense Enterprise on Windows permissions](/apps/connectors/business-intelligence/qlik-sense-enterprise-on-windows/how-tos/how-.



## Crawl Redash
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Redash permissions](/apps/connectors/business-intelligence/redash/how-tos/set-up-redash), you can establish a connection between Atlan and Redash.



## Crawl Redpanda Kafka
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Redpanda Kafka permissions](/apps/connectors/messaging/redpanda-kafka/how-tos/set-up-redpanda-kafka), you can establish a connection between Atlan and Redpanda Kafka.



## Crawl S3 assets
(source: https://docs.atlan.com/tags/crawl)

Configure and run the S3 crawler to catalog your Amazon S3 buckets and objects in Atlan.



## Crawl Salesforce
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [Salesforce user permissions](/apps/connectors/crm/salesforce/how-tos/set-up-salesforce), you can establish a connection between Atlan and Salesforce.



## Crawl SAP ECC
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from your SAP ECC system, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl SAP HANA
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the SAP HANA permissions](/apps/connectors/database/sap-hana/how-tos/set-up-sap-hana), you can establish a connection between Atlan and SAP HANA.



## Crawl SAP S/4HANA
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from your SAP S/4HANA system, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl Sigma
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Sigma permissions](/apps/connectors/business-intelligence/sigma/how-tos/set-up-sigma), you can establish a connection between Atlan and Sigma.



## Crawl Sisense
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Sisense permissions](/apps/connectors/business-intelligence/sisense/how-tos/set-up-sisense), you can establish a connection between Atlan and Sisense.



## Crawl Snowflake
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from Snowflake, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl Soda
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the Soda permissions](/apps/connectors/observability/soda/how-tos/set-up-soda), you can establish a connection between Atlan and Soda.



## Crawl Tableau
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from Tableau, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Crawl Teradata
(source: https://docs.atlan.com/tags/crawl)

Once you have configured the [Teradata user permissions](/apps/connectors/database/teradata/how-tos/set-up-teradata), you can establish a connection between Atlan and Teradata.



## Crawl ThoughtSpot
(source: https://docs.atlan.com/tags/crawl)

Once you have [configured the ThoughtSpot permissions](/apps/connectors/business-intelligence/thoughtspot/how-tos/set-up-thoughtspot), you can establish a connection between Atlan and ThoughtSpot.



## Crawl Trino
(source: https://docs.atlan.com/tags/crawl)

To crawl metadata from Trino, review the [order of operations](/product/connections/how-tos/order-workflows) and then complete the following steps.



## Disable data access
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will need to be an admin user in Atlan to configure these options.



## Does lineage only cover calculated fields for Tableau dashboards?
(source: https://docs.atlan.com/tags/crawl)

Atlan displays upstream as well as downstream lineage for [Tableau dashboards](/apps/connectors/business-intelligence/tableau/references/what-does-atlan-crawl-f.



## Enrich Atlan through dbt
(source: https://docs.atlan.com/tags/crawl)

Beyond the default mapped [dbt Cloud](/apps/connectors/etl-tools/dbt/references/what-does-atlan-crawl-from-dbt-cloud) or [dbt Core](/apps/connectors/etl-tools/dbt/references/what-does-atlan-crawl-from-dbt-core) properties, you can update any of Atlan's metadata attributes (except for `name`, `tenantId`, and `qualifiedName`) through your dbt model's `meta` property.



## extract lineage and usage from Databricks
(source: https://docs.atlan.com/tags/crawl)

Once you have [crawled assets from Databricks](/apps/connectors/data-warehouses/databricks/how-tos/crawl-databricks), you can retrieve lineage from [Unity Catalog](https://docs.databricks.com/data-governance/unity-catalog/index.html) and [usage and popularity metrics](/product/capabilities/usage-and-popularity/how-tos/interpret-usage-metrics) from [query history](https://docs.databricks.com/api/workspace/queryhistory/list) or system tables. This is supported for all [three authentication methods](/apps/connectors/data-warehouses/databricks/how-tos/set-up-databricks): personal access token, AWS service principal, and Azure service principal.



## Manage Databricks tags
(source: https://docs.atlan.com/tags/crawl)

You must have a [Unity Catalog-enabled workspace](https://docs.databricks.com/en/data-governance/unity-catalog/get-started.html) and SQL warehouse configured to import Databricks tags in Atlan.



## Manage dbt tags
(source: https://docs.atlan.com/tags/crawl)

Atlan imports your [dbt tags](https://docs.getdbt.com/references/resource-configs/tags) and allows you to update your dbt assets with the imported tags.



## Manage Google BigQuery tags
(source: https://docs.atlan.com/tags/crawl)

Atlan imports your [Google BigQuery tags](https://docs.getdbt.com/references/resource-configs/tags) and allows you to update your Google BigQuery assets with the imported tags. Note that object tagging in Google BigQuery currently requires [Enterprise edition or higher](https://cloud.google.com/bigquery/docs/editions-intro#editions_features).



## Manage Snowflake tags
(source: https://docs.atlan.com/tags/crawl)

You can import your Snowflake tags to Atlan through one-way tag sync. The synced Snowflake tags will be matched to corresponding tags in Atlan through case-insensitive name match and your Snowflake assets will be enriched with their synced tags from Snowflake.



## Mine Amazon Redshift
(source: https://docs.atlan.com/tags/crawl)

Once you have [crawled assets from Amazon Redshift](/apps/connectors/data-warehouses/amazon-redshift/how-tos/crawl-amazon-redshift), you can mine its query history to construct lineage and retrieve [usage and popularity metrics](/product/capabilities/usage-and-popularity/how-tos/interpret-usage-metrics).



## Mine Google BigQuery
(source: https://docs.atlan.com/tags/crawl)

Once you have [crawled assets from Google BigQuery](/apps/connectors/data-warehouses/google-bigquery/how-tos/crawl-google-bigquery), you can mine its query history to construct lineage.



## Mine Microsoft Azure Synapse Analytics
(source: https://docs.atlan.com/tags/crawl)

Learn about mine microsoft azure synapse analytics.



## Mine Microsoft Power BI
(source: https://docs.atlan.com/tags/crawl)

Once you have crawled assets from Microsoft Power BI, you can mine its activity events to generate usage metrics.



## Mine queries through S3
(source: https://docs.atlan.com/tags/crawl)

Once you have crawled assets from a supported connector, you can mine query history.



## Mine Snowflake
(source: https://docs.atlan.com/tags/crawl)

Once you have [crawled assets from Snowflake](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake), you can mine its query history to construct lineage.



## Mine Teradata
(source: https://docs.atlan.com/tags/crawl)

Once you have [crawled assets from Teradata](/apps/connectors/database/teradata/how-tos/crawl-teradata), you can mine its query history to construct lineage.



## order workflows
(source: https://docs.atlan.com/tags/crawl)

The [order of operations](/product/connections/how-tos/order-workflows#order-of-operations) you run in Atlan is important. Follow the specific workflow sequence outlined below when crawling [data tools](/product/connections/references/supported-sources). The right order particularly ensures that lineage is constructed without needing to rerun crawlers.



## Preflight checks for Aiven Kafka
(source: https://docs.atlan.com/tags/crawl)

Before [running the Aiven Kafka crawler](/apps/connectors/messaging/aiven-kafka/how-tos/crawl-aiven-kafka), you can run [preflight checks](/product/conne.



## Preflight checks for Amazon MSK
(source: https://docs.atlan.com/tags/crawl)

Before [running the Amazon MSK crawler](/apps/connectors/messaging/amazon-msk/how-tos/crawl-amazon-msk), you can run [preflight checks](/product/connecti.



## Preflight checks for Amazon QuickSight
(source: https://docs.atlan.com/tags/crawl)

The [ListAnalyses](https://docs.aws.amazon.com/quicksight/latest/APIReference/API_ListAnalyses.html) REST API is used to fetch the actual list of analyses for which the user has view permission.



## Preflight checks for Amazon Redshift
(source: https://docs.atlan.com/tags/crawl)

Before [running the Amazon Redshift crawler](/apps/connectors/data-warehouses/amazon-redshift/how-tos/crawl-amazon-redshift), you can run [preflight chec.



## Preflight checks for Apache Kafka
(source: https://docs.atlan.com/tags/crawl)

Before [running the Apache Kafka crawler](/apps/connectors/messaging/apache-kafka/how-tos/crawl-apache-kafka), run [preflight checks](/product/connection.



## Preflight checks for Confluent Schema Registry
(source: https://docs.atlan.com/tags/crawl)

Before [running the Confluent Schema Registry crawler](/apps/connectors/schema/confluent-schema-registry/how-tos/crawl-confluent-schema-registry), you ca.



## Preflight checks for Databricks
(source: https://docs.atlan.com/tags/crawl)

Before [running the Databricks crawler](/apps/connectors/data-warehouses/databricks/how-tos/crawl-databricks), you can run [preflight checks](/product/co.



## Preflight checks for DataStax Enterprise
(source: https://docs.atlan.com/tags/crawl)

Preflight checks for DataStax Enterprise



## Preflight checks for dbt
(source: https://docs.atlan.com/tags/crawl)

This checks if manifest files are present in the provided bucket and prefix.



## Preflight checks for Domo
(source: https://docs.atlan.com/tags/crawl)

Atlan uses the [DataSet API](https://developer.domo.com/portal/72ae9b3e80374-list-data-sets) to fetch dataset metadata from Domo.



## Preflight checks for Fivetran
(source: https://docs.atlan.com/tags/crawl)

Learn about preflight checks for fivetran.



## Preflight checks for Google BigQuery
(source: https://docs.atlan.com/tags/crawl)

Each request requires an OAuth 2.0 access token generated via the [service account key](https://cloud.google.com/docs/authentication#service-accounts).



## Preflight checks for Hive
(source: https://docs.atlan.com/tags/crawl)

Before [running the Hive crawler](/apps/connectors/database/hive/how-tos/crawl-hive), you can run [preflight checks](/product/connections/concepts/what-a.



## Preflight checks for Looker
(source: https://docs.atlan.com/tags/crawl)

First, the list of projects in the _Include Projects_ and _Exclude Projects_ fields is determined. Next, the [Query Projects](https://developers.looker.com/api/explorer/3.1/methods/Project#get_all_projects) REST API is used to fetch the actual list of projects for which the user has [view capability](https://cloud.google.com/looker/docs/access-control-and-permission-management).



## Preflight checks for Metabase
(source: https://docs.atlan.com/tags/crawl)

Before [running the Metabase crawler](/apps/connectors/business-intelligence/metabase/how-tos/crawl-metabase), you can run [preflight checks](/product/co.



## Preflight checks for Microsoft Azure Data Factory
(source: https://docs.atlan.com/tags/crawl)

Before [running the Microsoft Azure Data Factory crawler](/apps/connectors/etl-tools/microsoft-azure-data-factory/how-tos/crawl-microsoft-azure-data-fact.



## Preflight checks for Microsoft Azure Synapse Analytics
(source: https://docs.atlan.com/tags/crawl)

This check is performed for both [basic](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics) and [service principal](/apps/connectors/data-warehouses/microsoft-azure-synapse-analytics/how-tos/set-up-microsoft-azure-synapse-analytics) authentication method.



## Preflight checks for Microsoft Power BI
(source: https://docs.atlan.com/tags/crawl)

Before [running the Microsoft Power BI crawler](/apps/connectors/business-intelligence/microsoft-power-bi/how-tos/crawl-microsoft-power-bi), you can run.



## Preflight checks for Microsoft SQL Server
(source: https://docs.atlan.com/tags/crawl)

Before [running the Microsoft SQL Server crawler](/apps/connectors/database/microsoft-sql-server/how-tos/crawl-microsoft-sql-server), you can run [prefli.



## Preflight checks for MicroStrategy
(source: https://docs.atlan.com/tags/crawl)

First, the list of projects in the _Include Projects_ and _Exclude Projects_ fields is determined. Next,Â the [Get Projects REST API](https://demo.microstrategy.com/MicroStrategyLibrary/api-docs/index.html#/Projects/getProjects_1) is used to fetch the actual list of projects for which the user has permissions.



## Preflight checks for Mode
(source: https://docs.atlan.com/tags/crawl)

Before [running the Mode crawler](/apps/connectors/business-intelligence/mode/how-tos/crawl-mode), you can run [preflight checks](/product/connections/co.



## Preflight checks for Monte Carlo
(source: https://docs.atlan.com/tags/crawl)

Before [running the Monte Carlo crawler](/apps/connectors/observability/monte-carlo/how-tos/crawl-monte-carlo), you can run [preflight checks](/product/c.



## Preflight checks for MySQL
(source: https://docs.atlan.com/tags/crawl)

Before [running the MySQL crawler](/apps/connectors/database/mysql/how-tos/crawl-mysql), you can run [preflight checks](/product/connections/concepts/wha.



## Preflight checks for Oracle
(source: https://docs.atlan.com/tags/crawl)

Before [running the Oracle crawler](/apps/connectors/database/oracle/how-tos/crawl-oracle), you can run [preflight checks](/product/connections/concepts/.



## Preflight checks for PostgreSQL
(source: https://docs.atlan.com/tags/crawl)

Before [running the PostgreSQL crawler](/apps/connectors/database/postgresql/how-tos/crawl-postgresql), you can run [preflight checks](/product/connectio.



## Preflight checks for PrestoSQL
(source: https://docs.atlan.com/tags/crawl)

Before [running the PrestoSQL crawler](/apps/connectors/database/prestosql/how-tos/crawl-prestosql), you can run [preflight checks](/product/connections/.



## Preflight checks for Qlik Sense Cloud
(source: https://docs.atlan.com/tags/crawl)

This check tests for access to datasets and other Qlik objects.



## Preflight checks for Redash
(source: https://docs.atlan.com/tags/crawl)

Before [running the Redash crawler](/apps/connectors/business-intelligence/redash/how-tos/crawl-redash), you can run [preflight checks](/product/connecti.



## Preflight checks for Redpanda Kafka
(source: https://docs.atlan.com/tags/crawl)

Before [running the Redpanda Kafka crawler](/apps/connectors/messaging/redpanda-kafka/how-tos/crawl-redpanda-kafka), you can run [preflight checks](/prod.



## Preflight checks for Salesforce
(source: https://docs.atlan.com/tags/crawl)

Before [running the Salesforce crawler](/apps/connectors/crm/salesforce/how-tos/crawl-salesforce), you can run [preflight checks](/product/connections/co.



## Preflight checks for SAP S/4HANA
(source: https://docs.atlan.com/tags/crawl)

Preflight checks for SAP S/4HANA <Badge variant="preview" text="Private Preview" link="/get-started/references/product-release-stages#private-preview" />



## Preflight checks for Sigma
(source: https://docs.atlan.com/tags/crawl)

First, the list of workbooks in the _Include Workbooks_Â and _Exclude Workbooks_ fields is determined. Next, the [List Workbooks](https://help.sigmacomputing.com/hc/en-us/articles/4408555666323) REST API is used to fetch the actual list of workbooks for which the user credentials have view permission.



## Preflight checks for Sisense
(source: https://docs.atlan.com/tags/crawl)

Atlan uses the [Folders API](https://sisense.dev/guides/restApi/v1/?platform=linux&spec=L2023.6#/folders) to check if it's responding with a response status code 200.



## Preflight checks for Snowflake
(source: https://docs.atlan.com/tags/crawl)

Before [running the Snowflake crawler](/apps/connectors/data-warehouses/snowflake/how-tos/crawl-snowflake), you can run [preflight checks](/product/conne.



## Preflight checks for Soda
(source: https://docs.atlan.com/tags/crawl)

Learn about preflight checks for soda



## Preflight checks for Tableau
(source: https://docs.atlan.com/tags/crawl)

The [Server Info](https://help.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref_server.htm#server_info) REST API is used to fetch the `restApiVersion` value.



## Preflight checks for Teradata
(source: https://docs.atlan.com/tags/crawl)

Before [running the Teradata crawler](/apps/connectors/database/teradata/how-tos/crawl-teradata), you can run [preflight checks](/product/connections/con.



## Preflight checks for Trino
(source: https://docs.atlan.com/tags/crawl)

Before [running the Trino crawler](/apps/connectors/database/trino/how-tos/crawl-trino), you can run [preflight checks](/product/connections/concepts/wha.



## provide SSL certificates
(source: https://docs.atlan.com/tags/crawl)

SSL (Secure Sockets Layer) encryption helps establish a secure connection between your data source and Atlan. Atlan currently only supports SSL certificates for [crawling Tableau](/apps/connectors/business-intelligence/tableau/how-tos/crawl-tableau).



## Set up a private network link to Amazon Athena
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will need your Amazon Athena or AWS administrator involved - you may not have access yourself to complete these steps.



## Set up Amazon Redshift
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will need your Amazon Redshift administrator to run these commands - you may not have access yourself.



## Set up Amazon S3
(source: https://docs.atlan.com/tags/crawl)

Create AWS IAM permissions and credentials for Atlan to access and catalog your S3 buckets and objects.



## Set up AWS Glue
(source: https://docs.atlan.com/tags/crawl)

Learn about set up aws glue.



## Set up BigID
(source: https://docs.atlan.com/tags/crawl)

Create a BigID system user and API token for Atlan integration.



## Set up Confluent Schema Registry
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your Schema Registry administrator to complete these steps - you may not have access yourself.



## Set up DataStax Enterprise
(source: https://docs.atlan.com/tags/crawl)

Set up DataStax Enterprise



## Set up dbt Cloud
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your dbt Cloud administrator to complete these steps - you may not have access yourself.



## Set up Domo
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will need your Domo administrator to complete these steps - you may not have access yourself.



## Set up Fivetran
(source: https://docs.atlan.com/tags/crawl)

Learn about set up fivetran.



## Set up Google BigQuery
(source: https://docs.atlan.com/tags/crawl)

You must be a Google BigQuery administrator to run these commands. For more information, see [Google Cloud's Granting, changing, and revoking access to resources](https://cloud.google.com/iam/docs/granting-changing-revoking-access).



## Set up Google Cloud Storage
(source: https://docs.atlan.com/tags/crawl)

Configure Google Cloud Storage for secure metadata ingestion with Atlan.



## Set up Hive
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will need your Hadoop administrator to run these commands - you may not have access yourself.



## Set up IBM Cognos Analytics
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You must be an IBM Cognos Analytics administrator to complete these steps - you may not have access yourself.



## Set up Inventory reports
(source: https://docs.atlan.com/tags/crawl)

Create Inventory report for Amazon S3 in case of inventory based ingestion through the crawler.



## Set up Looker
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your Looker administrator to run these commands - you may not have access yourself.



## Set up Microsoft Azure Cosmos DB
(source: https://docs.atlan.com/tags/crawl)

If your Microsoft Azure Cosmos DB deployment includes a mix of vCore- and RU-based accounts, you must configure both to fetch metadata. You can then use the _vCore and RU_ deployment option to [crawl your Microsoft Azure Cosmos DB assets](/apps/connectors/database/microsoft-azure-cosmos-db/how-tos/crawl-microsoft-azure-cosmos-db).



## Set up Microsoft Azure Synapse Analytics
(source: https://docs.atlan.com/tags/crawl)

Atlan supports crawling the following with the Microsoft Azure Synapse Analytics package:.



## Set up Microsoft SQL Server
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your Microsoft SQL Server administrator to run these commands - you may not have access yourself.



## Set up MicroStrategy
(source: https://docs.atlan.com/tags/crawl)

Atlan supports the basic authentication method for fetching metadata from MicroStrategy. This method uses a username and password to fetch metadata.



## Set up Mode
(source: https://docs.atlan.com/tags/crawl)

If you do not see the prompts to enter details for the user above, you are probably already signed in to Mode. Sign out of Mode first, and then accept the invite in the service account email.



## Set up MongoDB
(source: https://docs.atlan.com/tags/crawl)

Atlan supports the basic authentication method for fetching metadata from MongoDB. This method uses a [username and password](#create-database-user-in-mongodb) to fetch metadata.



## Set up Monte Carlo
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your Monte Carlo [account owner](https://docs.getmontecarlo.com/docs/authorizationmanaged-roles-and-groups).



## Set up on-premises database access
(source: https://docs.atlan.com/tags/crawl)

In such cases you may want to decouple the extraction of metadata from its ingestion in Atlan. This approach gives you full control over your resources and metadata transfer to Atlan.



## Set up on-premises Databricks access
(source: https://docs.atlan.com/tags/crawl)

In some cases you will not be able to expose your Databricks instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.



## Set up on-premises IBM Cognos Analytics access
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will need access to a machine that can run Docker on-premises. You will also need your IBM Cognos Analytics instance details,.



## Set up on-premises Kafka access
(source: https://docs.atlan.com/tags/crawl)

In some cases you won't be able to expose your Kafka instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.



## Set up on-premises Looker access
(source: https://docs.atlan.com/tags/crawl)

In some cases you won't be able to expose your Looker instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.



## Set up on-premises Tableau access
(source: https://docs.atlan.com/tags/crawl)

In some cases you may not be able to expose your Tableau instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.



## Set up on-premises ThoughtSpot access
(source: https://docs.atlan.com/tags/crawl)

In some cases you will not be able to expose your ThoughtSpot instance for Atlan to crawl and ingest metadata. For example, this may happen when security requirements restrict access to sensitive, mission-critical data.



## Set up Oracle
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You need your Oracle database administrator or a similar role to run these commands - you may not have access yourself.



## Set up PostgreSQL
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your PostgreSQL administrator to run these commands - you may not have access yourself.



## Set up SAP HANA
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your SAP HANA administrator to run these commands - you may not have access yourself.



## Set up Sisense
(source: https://docs.atlan.com/tags/crawl)

Atlan supports the basic authentication method for fetching metadata from Sisense. This method uses a username and password to fetch metadata.



## Set up Snowflake
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You need your Snowflake administrator to run these commands - you may not have access yourself. :::.



## Set up Tableau
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your Tableau administrator to run these commands - you may not have access yourself.



## Set up Teradata
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your Teradata administrator to run these commands - you may not have access yourself.



## Set up ThoughtSpot
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your ThoughtSpot instance administrator to complete these steps - you may not have access yourself.



## Set up Trino
(source: https://docs.atlan.com/tags/crawl)

:::warning Who can do this? You will probably need your Trino administrator to run these commands - you may not have access yourself.



## Troubleshooting data models
(source: https://docs.atlan.com/tags/crawl)

What are the known limitations of data models in Atlan?



## Troubleshooting lineage
(source: https://docs.atlan.com/tags/crawl)

So you've crawled your source, and mined the queries, but lineage is missing. Why?



## update column metadata in Google Sheets
(source: https://docs.atlan.com/tags/crawl)

Once you've [connected Atlan with Google Sheets](/product/integrations/collaboration/spreadsheets/how-tos/integrate-atlan-with-google-sheets), you can import the column metadata for all your data assets in Atlan and make changes to them directly in Google Sheets.



## Update column metadata in Microsoft Excel
(source: https://docs.atlan.com/tags/crawl)

Once you've [connected Atlan with Microsoft Excel](/product/integrations/collaboration/spreadsheets/how-tos/integrate-atlan-with-microsoft-excel), you can import the column metadata for all your data assets in Atlan and make changes to them directly in Microsoft Excel.



## view data models
(source: https://docs.atlan.com/tags/crawl)

Once you have [ingested your ER model assets in Atlan](/product/capabilities/data-models/concepts/what-are-data-models), you can:.



## What does Atlan crawl from Aiven Kafka?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Aiven Kafka.



## What does Atlan crawl from Amazon Athena?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Amazon Athena.



## What does Atlan crawl from Amazon DynamoDB?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Amazon DynamoDB. Atlan also currently supports lineage between Amazon DynamoDB as a source to supported data warehouses as destinations, as enriched by Fivetran.



## What does Atlan crawl from Amazon MSK?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Amazon MSK.



## What does Atlan crawl from Amazon MWAA/OpenLineage?
(source: https://docs.atlan.com/tags/crawl)

Once you have [integrated Amazon MWAA/OpenLineage](/apps/connectors/lineage/amazon-mwaa-openlineage/how-tos/integrate-amazon-mwaa-openlineage), you can [.



## What does Atlan crawl from Amazon QuickSight?
(source: https://docs.atlan.com/tags/crawl)

Atlan currently supports lineage for the Amazon QuickSight connector to the following data sources:.



## What does Atlan crawl from Amazon Redshift?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Amazon Redshift.



## What does Atlan crawl from Amazon S3
(source: https://docs.atlan.com/tags/crawl)

Complete reference for the S3 assets and properties that Atlan crawls and maps during S3 cataloging.



## What does Atlan crawl from Anomalo?
(source: https://docs.atlan.com/tags/crawl)

Once you have [integrated Anomalo](/apps/connectors/observability/anomalo/how-tos/integrate-anomalo), Atlan will receive webhook events when checks are executed in Anomalo. These checks will be cataloged in Atlan to create a relationship with existing assets using the association information from the check.



## What does Atlan crawl from Apache Airflow/OpenLineage?
(source: https://docs.atlan.com/tags/crawl)

Once you have [integrated Apache Airflow/OpenLineage](/apps/connectors/lineage/apache-airflow-openlineage/how-tos/integrate-apache-airflow-openlineage),.



## What does Atlan crawl from Apache Kafka?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Apache Kafka.



## What does Atlan crawl from Apache Spark/OpenLineage?
(source: https://docs.atlan.com/tags/crawl)

Atlan maps the following assets and properties from Apache Spark/OpenLineage. Asset lineage support depends on the data sources that OpenLineage supports.



## What does Atlan crawl from Astronomer/OpenLineage?
(source: https://docs.atlan.com/tags/crawl)

Atlan maps the following assets and properties from Astronomer/OpenLineage. Asset lineage support depends on the [list of operators supported by OpenLineage](https://airflow.apache.org/docs/apache-airflow-providers-openlineage/1.6.0/supported_classes.html).



## What does Atlan crawl from AWS Glue?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from AWS Glue.



## What does Atlan crawl from BigID?
(source: https://docs.atlan.com/tags/crawl)

Reference guide for BigID metadata crawled by Atlan.



## What does Atlan crawl from Confluent Kafka?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Confluent Kafka.



## What does Atlan crawl from CrateDB?
(source: https://docs.atlan.com/tags/crawl)

Complete list of CrateDB assets and metadata properties extracted by Atlan during crawling



## What does Atlan crawl from Databricks?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Databricks.



## What does Atlan crawl from DataStax Enterprise?
(source: https://docs.atlan.com/tags/crawl)

What does Atlan crawl from DataStax Enterprise?



## What does Atlan crawl from Domo?
(source: https://docs.atlan.com/tags/crawl)

Atlan supports lineage for the following asset types:.



## What does Atlan crawl from Fivetran?
(source: https://docs.atlan.com/tags/crawl)

Learn about what does atlan crawl from fivetran?.



## What does Atlan crawl from Google BigQuery?
(source: https://docs.atlan.com/tags/crawl)

Atlan doesn't run any table scans. Atlan leverages the table preview options from [Google BigQuery](https://cloud.google.com/bigquery/docs/best-practices-costs#preview-data)Â that enable you to view data for free and without affecting any quotas using the `tabledata.list` API. Hence, [table](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#tables) asset previews in Atlan are already cost-optimized. However, this doesn't apply to [views](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#views) and [materialized views](/apps/connectors/data-warehouses/google-bigquery/references/what-does-atlan-crawl-from-google-bigquery#materialized-views).



## What does Atlan crawl from Google Cloud Composer/OpenLineage?
(source: https://docs.atlan.com/tags/crawl)

Atlan maps the following assets and properties from Google Cloud Composer/OpenLineage. Asset lineage support depends on the [list of operators supported by OpenLineage](https://airflow.apache.org/docs/apache-airflow-providers-openlineage/1.6.0/supported_classes.html).



## What does Atlan crawl from Google GCS
(source: https://docs.atlan.com/tags/crawl)

Complete reference for the GCS assets and properties that Atlan crawls and maps during GCS cataloging.



## What does Atlan crawl from Hive?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Hive.



## What does Atlan crawl from IBM Cognos Analytics?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from IBM Cognos Analytics.



## What does Atlan crawl from Looker?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Looker.



## What does Atlan crawl from Matillion?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Matillion.



## What does Atlan crawl from Microsoft Azure Cosmos DB?
(source: https://docs.atlan.com/tags/crawl)

Once you have [crawled Microsoft Azure Cosmos DB](/apps/connectors/database/microsoft-azure-cosmos-db/how-tos/crawl-microsoft-azure-cosmos-db), you can [.



## What does Atlan crawl from Microsoft Azure Data Factory?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Microsoft Azure Data Factory.



## What does Atlan crawl from Microsoft Azure Event Hubs?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Microsoft Azure Event Hubs.



## What does Atlan crawl from Microsoft Azure Synapse Analytics?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Microsoft Azure Synapse Analytics. Atlan also currently supports view-level lineage and cross-source lineage between BI tools and SQL sources.



## What does Atlan crawl from Microsoft Power BI?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Microsoft Power BI.



## What does Atlan crawl from Microsoft SQL Server?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Microsoft SQL Server.



## What does Atlan crawl from MicroStrategy?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from MicroStrategy.



## What does Atlan crawl from MongoDB?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from MongoDB. Atlan currently does not support lineage for MongoDB assets.



## What does Atlan crawl from Monte Carlo?
(source: https://docs.atlan.com/tags/crawl)

What does Atlan crawl from Monte Carlo? <Badge variant="preview" text="Private Preview" link="/get-started/references/product-release-stages#private-preview" />



## What does Atlan crawl from MySQL?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from MySQL.



## What does Atlan crawl from Oracle?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Oracle.



## What does Atlan crawl from PostgreSQL?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from PostgreSQL.



## What does Atlan crawl from PrestoSQL?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from PrestoSQL.



## What does Atlan crawl from Qlik Sense Cloud?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Qlik Sense Cloud.



## What does Atlan crawl from Qlik Sense Enterprise on Windows?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Qlik Sense Enterprise on Windows.



## What does Atlan crawl from Redash?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Redash.



## What does Atlan crawl from Redpanda Kafka?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Redpanda Kafka.



## What does Atlan crawl from Salesforce?
(source: https://docs.atlan.com/tags/crawl)

Atlan only performs GET requests on these five endpoints:.



## What does Atlan crawl from SAP ECC?
(source: https://docs.atlan.com/tags/crawl)

What does Atlan crawl from SAP ECC? <Badge variant="preview" text="Private Preview" link="/get-started/references/product-release-stages#private-preview" />



## What does Atlan crawl from SAP S/4HANA?
(source: https://docs.atlan.com/tags/crawl)

What does Atlan crawl from SAP S/4HANA? <Badge variant="preview" text="Private Preview" link="/get-started/references/product-release-stages#private-preview" />



## What does Atlan crawl from Sisense?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Sisense.



## What does Atlan crawl from Snowflake?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Snowflake.



## What does Atlan crawl from Soda?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls datasets and then filters out all the datasets without any checks. It then crawls the checks associated with each of the datasets with checks from Soda. These checks are cataloged in Atlan to create a relationship with existing assets using the association information from the dataset.



## What does Atlan crawl from Tableau?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Tableau.



## What does Atlan crawl from Teradata?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Teradata.



## What does Atlan crawl from ThoughtSpot?
(source: https://docs.atlan.com/tags/crawl)

Once you've [crawled ThoughtSpot](/apps/connectors/business-intelligence/thoughtspot/how-tos/crawl-thoughtspot), you can [use connector-specific filters].



## What does Atlan crawl from Trino?
(source: https://docs.atlan.com/tags/crawl)

Atlan crawls and maps the following assets and properties from Trino.



## What lineage does Atlan extract from Matillion?
(source: https://docs.atlan.com/tags/crawl)

Atlan uses Matillion's metadata API to generate lineage associated with [Matillion connectors](https://www.matillion.com/connectors). This is particularly useful for creating lineage between different tools.



## What lineage does Atlan extract from Microsoft Azure Data Factory?
(source: https://docs.atlan.com/tags/crawl)

Atlan uses the [Microsoft Azure Data Factory REST API](https://learn.microsoft.com/en-us/rest/api/datafactory/operation-groups?view=rest-datafactory-2018-06-01).



## What lineage does Atlan extract from Microsoft Power BI?
(source: https://docs.atlan.com/tags/crawl)

This document helps you understand how Atlan generates lineage to upstream SQL sources for your Microsoft Power BI assets using a custom query parser, and the steps you can take while developing reports and dashboards in Microsoft Power BI to create seamless lineage generation.



## When does Atlan become a personal data processor or subprocessor?
(source: https://docs.atlan.com/tags/crawl)

Atlan personnel do not have access to any customer instance unless specifically provided by the customer. Accordingly, in the event that a customer instance contains personal data and Atlan personnel are provided access to that instance, Atlan may act as a personal data processor. In addition, depending on whether the customer is a data controller or processor, Atlan may act as a data processor or subprocessor, respectively.



## Why does the description from Salesforce not show up in Atlan?
(source: https://docs.atlan.com/tags/crawl)

Atlan supports extracting and displaying description metadata for your [Salesforce objects](/apps/connectors/crm/salesforce/references/what-does-atlan-crawl-from-salesforce).
