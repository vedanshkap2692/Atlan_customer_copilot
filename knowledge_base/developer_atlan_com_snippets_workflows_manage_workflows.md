# Manage workflowsÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

Overview

Getting started

Common tasks

Asset-specific

Governance structures

Reference

ToolkitsToolkitsPackagesPackagesRunning exampleDefine via templateRender your packageDevelop your logicTest your logicRelease (GA)Widget referenceTypedefsTypedefsRunning exampleDefine via templateRender your modelTest your modelBind the SDKsWrite integration testTest baseline UXRelease (GA)TestingTesting

ToolkitsToolkitsPackagesPackagesRunning exampleDefine via templateRender your packageDevelop your logicTest your logicRelease (GA)Widget referenceTypedefsTypedefsRunning exampleDefine via templateRender your modelTest your modelBind the SDKsWrite integration testTest baseline UXRelease (GA)TestingTesting

PackagesPackagesRunning exampleDefine via templateRender your packageDevelop your logicTest your logicRelease (GA)Widget reference

Running example

Define via template

Render your package

Develop your logic

Test your logic

Release (GA)

Widget reference

TypedefsTypedefsRunning exampleDefine via templateRender your modelTest your modelBind the SDKsWrite integration testTest baseline UXRelease (GA)

Running example

Define via template

Render your model

Test your model

Bind the SDKs

Write integration test

Test baseline UX

Release (GA)

TestingTesting

Overview

Getting startedGetting startedOther important conceptsDocumentation conventionsIntegration optionsIntegration optionsCLIdbtJavaPythonKotlinScalaClojureGoEventsRaw REST APISite map

Other important concepts

Documentation conventions

Integration optionsIntegration optionsCLIdbtJavaPythonKotlinScalaClojureGoEventsRaw REST API

CLI

dbt

Java

Python

Kotlin

Scala

Clojure

Go

Events

Raw REST API

Site map

Common tasksCommon tasksCommon asset actionsCommon asset actionsCertify assetsManage announcementsChange descriptionChange ownersTag (classify) assetsChange custom metadataLink terms to assetsLink domains to assetsManage asset READMEsAdd asset resourcesManage asset relationships with attributesAsset CRUD operationsAsset CRUD operationsCreate an assetRetrieve an assetUpdate an assetDelete an assetFind and apply suggestionsRestore an assetReview changes to an assetReview accesses of an assetGet all assets that...Get all assets that...Search for assetsSearch examplesLineageLineageManage lineageTraverse lineageBulk updatesBulk updatesCombine multiple operationsUpdate multiple assetsEnd-to-end bulk updateEvent handlingEvent handlingWebhook <> LambdaWebhook <> LambdaSet up LambdaCode your logicDeploy your codeSet up webhookManage your webhook

Common asset actionsCommon asset actionsCertify assetsManage announcementsChange descriptionChange ownersTag (classify) assetsChange custom metadataLink terms to assetsLink domains to assetsManage asset READMEsAdd asset resourcesManage asset relationships with attributes

Certify assets

Manage announcements

Change description

Change owners

Tag (classify) assets

Change custom metadata

Link terms to assets

Link domains to assets

Manage asset READMEs

Add asset resources

Manage asset relationships with attributes

Asset CRUD operationsAsset CRUD operationsCreate an assetRetrieve an assetUpdate an assetDelete an assetFind and apply suggestionsRestore an assetReview changes to an assetReview accesses of an asset

Create an asset

Retrieve an asset

Update an asset

Delete an asset

Find and apply suggestions

Restore an asset

Review changes to an asset

Review accesses of an asset

Get all assets that...Get all assets that...Search for assetsSearch examples

Search for assets

Search examples

LineageLineageManage lineageTraverse lineage

Manage lineage

Traverse lineage

Bulk updatesBulk updatesCombine multiple operationsUpdate multiple assetsEnd-to-end bulk update

Combine multiple operations

Update multiple assets

End-to-end bulk update

Event handlingEvent handlingWebhook <> LambdaWebhook <> LambdaSet up LambdaCode your logicDeploy your codeSet up webhookManage your webhook

Webhook <> LambdaWebhook <> LambdaSet up LambdaCode your logicDeploy your codeSet up webhookManage your webhook

Set up Lambda

Code your logic

Deploy your code

Set up webhook

Manage your webhook

Asset-specificAsset-specificGlossary operationsGlossary operationsCreate objectsRetrieval by nameCreate a hierarchyCategorize termsTraverse category hierarchyCreating assetsCreating assetsManage relational assetsManage cube assetsManage object store assetsManage object store assetsManage AWS S3 assetsManage Azure Data Lake Storage assetsManage Google Cloud Storage assetsManage BI assetsManage BI assetsManage Google Data Studio assetsManage Preset assetsManage Superset assetsManage API assetsManage file assetsManage Airflow assetsManage Kafka assetsManage Azure Event Hub assetsManage App assetsManage AI assetsManage Insights assetsManage QuickSight assetsManage DocumentDB assetsManage Data Quality assetsManage Data Quality assetsManage Data Quality rulesConnector types and iconsData meshData meshManage data domainsManage data productsData contractsData contractsManage data contracts (via CLI)Manage data contracts (via SDK)Profiling and popularityProfiling and popularityManage column profilingManage popularity

Glossary operationsGlossary operationsCreate objectsRetrieval by nameCreate a hierarchyCategorize termsTraverse category hierarchy

Create objects

Retrieval by name

Create a hierarchy

Categorize terms

Traverse category hierarchy

Creating assetsCreating assetsManage relational assetsManage cube assetsManage object store assetsManage object store assetsManage AWS S3 assetsManage Azure Data Lake Storage assetsManage Google Cloud Storage assetsManage BI assetsManage BI assetsManage Google Data Studio assetsManage Preset assetsManage Superset assetsManage API assetsManage file assetsManage Airflow assetsManage Kafka assetsManage Azure Event Hub assetsManage App assetsManage AI assetsManage Insights assetsManage QuickSight assetsManage DocumentDB assetsManage Data Quality assetsManage Data Quality assetsManage Data Quality rulesConnector types and icons

Manage relational assets

Manage cube assets

Manage object store assetsManage object store assetsManage AWS S3 assetsManage Azure Data Lake Storage assetsManage Google Cloud Storage assets

Manage AWS S3 assets

Manage Azure Data Lake Storage assets

Manage Google Cloud Storage assets

Manage BI assetsManage BI assetsManage Google Data Studio assetsManage Preset assetsManage Superset assets

Manage Google Data Studio assets

Manage Preset assets

Manage Superset assets

Manage API assets

Manage file assets

Manage Airflow assets

Manage Kafka assets

Manage Azure Event Hub assets

Manage App assets

Manage AI assets

Manage Insights assets

Manage QuickSight assets

Manage DocumentDB assets

Manage Data Quality assetsManage Data Quality assetsManage Data Quality rules

Manage Data Quality rules

Connector types and icons

Data meshData meshManage data domainsManage data products

Manage data domains

Manage data products

Data contractsData contractsManage data contracts (via CLI)Manage data contracts (via SDK)

Manage data contracts (via CLI)

Manage data contracts (via SDK)

Profiling and popularityProfiling and popularityManage column profilingManage popularity

Manage column profiling

Manage popularity

Governance structuresGovernance structuresCustom metadataCustom metadataCreate custom metadataRetrieve custom metadataUpdate custom metadataDelete custom metadataManage badgesManage options (enumerations)Tag managementTag managementManage Atlan tagsMonitor propagationAccess controlAccess controlManage personasManage purposesManage policiesAccess eventsAPI token managementRun queries on an assetUsers and groupsUsers and groupsCreate users and groupsRetrieve users and groupsUpdate users and groupsDelete users and groupsManage SSO group mappingPackages and workflowsPackages and workflowsManage workflowsManage workflowsTable of contentsRetrieve workflowBy IDBy typeCreate workflow credentialsRetrieve all workflow credentialsUpdate workflow source credentialsHard-delete an workflow credentialsUpdate workflow configurationRetrieve workflow runBy IDBy status and time rangeRetrieve all workflow runsBy their phase:Stop a running workflowDelete a workflowManage workflow schedulesSupported packagesSupported packagesAthena assetsAsset importAsset export (basic)API token connection adminBigQuery assetsConnection deleteConfluent Kafka assetsdbt assetsDynamoDB assetsDatabricks assetsDatabricks minerFivetran enrichmentGlue assetsLooker assetsLineage builderLineage generator (no transformation)MongoDB assetsOracle assetsPostgres assetsPowerBI assetsRedshift assetsRelational assets builderSnowflake assetsSnowflake minerSigma assetsSQL Server assetsTableau assetsFile managementFile management

Custom metadataCustom metadataCreate custom metadataRetrieve custom metadataUpdate custom metadataDelete custom metadataManage badgesManage options (enumerations)

Create custom metadata

Retrieve custom metadata

Update custom metadata

Delete custom metadata

Manage badges

Manage options (enumerations)

Tag managementTag managementManage Atlan tagsMonitor propagation

Manage Atlan tags

Monitor propagation

Access controlAccess controlManage personasManage purposesManage policiesAccess eventsAPI token managementRun queries on an asset

Manage personas

Manage purposes

Manage policies

Access events

API token management

Run queries on an asset

Users and groupsUsers and groupsCreate users and groupsRetrieve users and groupsUpdate users and groupsDelete users and groupsManage SSO group mapping

Create users and groups

Retrieve users and groups

Update users and groups

Delete users and groups

Manage SSO group mapping

Packages and workflowsPackages and workflowsManage workflowsManage workflowsTable of contentsRetrieve workflowBy IDBy typeCreate workflow credentialsRetrieve all workflow credentialsUpdate workflow source credentialsHard-delete an workflow credentialsUpdate workflow configurationRetrieve workflow runBy IDBy status and time rangeRetrieve all workflow runsBy their phase:Stop a running workflowDelete a workflowManage workflow schedulesSupported packagesSupported packagesAthena assetsAsset importAsset export (basic)API token connection adminBigQuery assetsConnection deleteConfluent Kafka assetsdbt assetsDynamoDB assetsDatabricks assetsDatabricks minerFivetran enrichmentGlue assetsLooker assetsLineage builderLineage generator (no transformation)MongoDB assetsOracle assetsPostgres assetsPowerBI assetsRedshift assetsRelational assets builderSnowflake assetsSnowflake minerSigma assetsSQL Server assetsTableau assets

Manage workflowsManage workflowsTable of contentsRetrieve workflowBy IDBy typeCreate workflow credentialsRetrieve all workflow credentialsUpdate workflow source credentialsHard-delete an workflow credentialsUpdate workflow configurationRetrieve workflow runBy IDBy status and time rangeRetrieve all workflow runsBy their phase:Stop a running workflowDelete a workflow

Retrieve workflowBy IDBy type

By ID

By type

Create workflow credentials

Retrieve all workflow credentials

Update workflow source credentials

Hard-delete an workflow credentials

Update workflow configuration

Retrieve workflow runBy IDBy status and time range

By ID

By status and time range

Retrieve all workflow runsBy their phase:

By their phase:

Stop a running workflow

Delete a workflow

Manage workflow schedules

Supported packagesSupported packagesAthena assetsAsset importAsset export (basic)API token connection adminBigQuery assetsConnection deleteConfluent Kafka assetsdbt assetsDynamoDB assetsDatabricks assetsDatabricks minerFivetran enrichmentGlue assetsLooker assetsLineage builderLineage generator (no transformation)MongoDB assetsOracle assetsPostgres assetsPowerBI assetsRedshift assetsRelational assets builderSnowflake assetsSnowflake minerSigma assetsSQL Server assetsTableau assets

Athena assets

Asset import

Asset export (basic)

API token connection admin

BigQuery assets

Connection delete

Confluent Kafka assets

dbt assets

DynamoDB assets

Databricks assets

Databricks miner

Fivetran enrichment

Glue assets

Looker assets

Lineage builder

Lineage generator (no transformation)

MongoDB assets

Oracle assets

Postgres assets

PowerBI assets

Redshift assets

Relational assets builder

Snowflake assets

Snowflake miner

Sigma assets

SQL Server assets

Tableau assets

File managementFile management

ReferenceReferenceSearchingSearchingQueryingQueryingTerm-level queriesFull text queriesRank feature queriesCompound queriesSearchable fieldsSearchable fieldsCommon search fieldsGlossary-specific search fieldsLimiting detailsSorting search resultsPaging search resultsAggregating search resultsEventsEventsEvent triggersEvent triggersAsset is createdAsset is updatedAsset is deletedCustom metadata is addedCustom metadata is removedAsset is taggedAsset is untaggedLineage is createdEvent typesEvent typesENTITY_CREATEENTITY_UPDATEENTITY_DELETEBUSINESS_ATTRIBUTE_UPDATECLASSIFICATION_ADDCLASSIFICATION_DELETESpecificationsSpecificationsData contract specOpenLineage specTypesTypesCoreCoreReferenceableAssetConnectionCatalogTagTagAttachmentAccess controlAccess controlPersonaPurposeAuthPolicyAuthServiceBusinessPolicyBusinessPolicyExceptionBusinessPolicyIncidentBusinessPolicyLogIncidentLineageLineageColumnProcessBIProcessResourcesResourcesLinkFileReadmeReadmeTemplateBadgeWorkflowsWorkflowsWorkflowWorkflowRunTaskStructsStructsActionAuthPolicyConditionAuthPolicyValidityScheduleAwsCloudWatchMetricAwsTagAzureTagBadgeConditionBusinessPolicyRuleByocSsoConfigColumnValueFrequencyMapDbtMetricFilterDbtJobRunGoogleLabelGoogleTagHistogramKafkaTopicConsumptionMCRuleComparisonMCRuleSchedulePopularityInsightsSourceTagAttachmentSourceTagAttachmentValueSourceTagAttributeStarredDetailsEnumerationsEnumerationsAdfActivityStateADLSAccessTierADLSAccountStatusADLSEncryptionTypesADLSLeaseStateADLSLeaseStatusADLSObjectArchiveStatusADLSObjectTypeADLSPerformanceADLSProvisionStateADLSReplicationTypeADLSStorageKindAPIQueryParamTypeEnumatlas_operationAtlasGlossaryCategoryTypeAtlasGlossaryTermTypeAtlasGlossaryTypeAtlasGlossaryTermAssignmentStatusAtlasGlossaryTermRelationshipStatusAuthPolicyCategoryAuthPolicyResourceCategoryAuthPolicyTypecertificate_statusDataGlossaryDataProductCriticalityDataProductSensitivityDataProductStatusDataProductVisibilityDomoCardTypeDynamoDBSecondaryIndexProjectionTypeDynamoDBStatusfile_typeFivetranConnectorStatusFivetranProcessStatusgoogle_datastudio_asset_typeicon_typeincident_severitykafka_topic_cleanup_policykafka_topic_compression_typematillion_job_typeModelCardinalityTypeMongoDBCollectionValidationActionMongoDBCollectionValidationLevelOpenLineageRunStatepowerbi_endorsementquery_username_strategyquick_sight_analysis_statusquick_sight_dataset_field_typequick_sight_dataset_import_modequick_sight_folder_typeSchemaRegistrySchemaCompatibilitySchemaRegistrySchemaTypeSourceCostUnitTypetable_typeWorkflowRunStatusWorkflowRunTypeWorkflowStatusWorkflowTypeAbstractionsAbstractionsBICloudInsightObjectStoreEventStoreDataQualityMetricNoSQLSchemaRegistryGlossaryGlossaryAtlasGlossaryAtlasGlossaryCategoryAtlasGlossaryTermData meshData meshDataDomainDataProductDataContractStakeholderStakeholderTitleRelational databasesRelational databasesDatabaseSchemaTableViewMaterialisedViewColumnQueryTablePartitionCalculationViewBigqueryTagDatabricksUnityCatalogTagSnowflakeDynamicTableSnowflakePipeSnowflakeStreamSnowflakeTagProcedureFunctionSQLQuery organizationQuery organizationNamespaceCollectionFolderCubesCubesCubeCubeDimensionCubeHierarchyCubeFieldAPIsAPIsAPIPathAPISpecAPIObjectAPIQueryAPIFieldAirflowAirflowAirflowDagAirflowTaskAmazonAmazonAmazon DynamoDBAmazon DynamoDBDynamoDBTableDynamoDBSecondaryIndexDynamoDBGlobalSecondaryIndexDynamoDBLocalSecondaryIndexAWS S3AWS S3S3BucketS3ObjectAmazon QuickSightAmazon QuickSightQuickSightAnalysisQuickSightAnalysisVisualQuickSightDashboardQuickSightDashboardVisualQuickSightDatasetQuickSightDatasetFieldQuickSightFolderAnaplanAnaplanAnaplanWorkspaceAnaplanAppAnaplanPageAnaplanModelAnaplanModuleAnaplanListAnaplanSystemDimensionAnaplanDimensionAnaplanLineItemAnaplanViewAnomaloAnomaloAnomaloCheckAppAppApplicationApplicationFieldMicrosoft AzureMicrosoft AzureAzure Data FactoryAzure Data FactoryAdfActivityAdfDataflowAdfDatasetAdfLinkedserviceAdfPipelineAzure Data Lake StorageAzure Data Lake StorageADLSAccountADLSContainerADLSObjectAzure Event HubAzure Event HubAzureEventHubAzureEventHubConsumerGroupAzure Service BusAzure Service BusAzureServiceBusNamespaceAzureServiceBusSchemaAzureServiceBusTopicCosmos DBCosmos DBCosmosMongoDBAccountCosmosMongoDBCollectionCosmosMongoDBDatabaseCogniteCogniteCognite3DModelCogniteAssetCogniteEventCogniteFileCogniteSequenceCogniteTimeseriesCustomCustomCustomEntityDataverseDataverseDataverseEntityDataverseAttributedbtdbtDbtColumnProcessDbtMetricDbtModelDbtModelColumnDbtProcessDbtSourceDbtTagDbtTestDomoDomoDomoCardDomoDashboardDomoDatasetDomoDatasetColumnDocumentDBDocumentDBDocumentDBCollectionDocumentDBDatabaseFivetranFivetranFivetranConnectorGoogleGoogleGoogle Cloud StorageGoogle Cloud StorageGCSBucketGCSObjectGoogle Data StudioGoogle Data StudioDataStudioAssetIBMIBMIBMCognosCognosCognosDashboardCognosDatasourceCognosExplorationCognosFileCognosFolderCognosModuleCognosPackageCognosReportKafkaKafkaKafkaConsumerGroupKafkaTopicLookerLookerLookerDashboardLookerExploreLookerFieldLookerFolderLookerLookLookerModelLookerProjectLookerQueryLookerTileLookerViewMatillionMatillionMatillionComponentMatillionGroupMatillionJobMatillionProjectMetabaseMetabaseMetabaseCollectionMetabaseDashboardMetabaseQuestionMicroStrategyMicroStrategyMicroStrategyAttributeMicroStrategyCubeMicroStrategyDocumentMicroStrategyDossierMicroStrategyFactMicroStrategyMetricMicroStrategyProjectMicroStrategyReportMicroStrategyVisualizationModeModeModeChartModeCollectionModeQueryModeReportModeWorkspaceModelsModelsModelAttributeModelAttributeAssociationModelDataModelModelEntityModelEntityAssociationModelVersionMongoDBMongoDBMongoDBCollectionMongDBDatabaseMonte CarloMonte CarloMCIncidentMCMonitorPower BIPower BIPower BIPowerBIColumnPowerBIDashboardPowerBIDataflowPowerBIDataflowEntityColumnPowerBIDatasetPowerBIDatasourcePowerBIMeasurePowerBIPagePowerBIReportPowerBITablePowerBITilePowerBIWorkspacePresetPresetPresetChartPresetDashboardPresetDatasetPresetWorkspaceQlikQlikQlikAppQlikChartQlikDatasetQlikSheetQlikSpaceQlikStreamRedashRedashRedashDashboardRedashQueryRedashVisualizationSalesforceSalesforceSalesforceDashboardSalesforceFieldSalesforceObjectSalesforceOrganizationSalesforceReportSaaSSigmaSigmaSigmaWorkbookSigmaPageSigmaDataElementSigmaDataElementFieldSigmaDatasetSigmaDatasetColumnSisenseSisenseSisenseDashboardSisenseDatamodelSisenseDatamodelTableSisenseFolderSisenseWidgetSodaSodaSodaCheckSparkSparkSparkJobSupersetSupersetSupersetChartSupersetDashboardSupersetDatasetTableauTableauTableauCalculatedFieldTableauDashboardTableauDatasourceTableauDatasourceFieldTableauFlowTableauMetricTableauProjectTableauSiteTableauWorkbookTableauWorksheetThoughtSpotThoughtSpotThoughtspotAnswerThoughtspotColumnThoughtspotDashletThoughtspotLiveboardThoughtspotTableThoughtspotViewThoughtspotWorksheetEndpoints

SearchingSearchingQueryingQueryingTerm-level queriesFull text queriesRank feature queriesCompound queriesSearchable fieldsSearchable fieldsCommon search fieldsGlossary-specific search fieldsLimiting detailsSorting search resultsPaging search resultsAggregating search results

QueryingQueryingTerm-level queriesFull text queriesRank feature queriesCompound queries

Term-level queries

Full text queries

Rank feature queries

Compound queries

Searchable fieldsSearchable fieldsCommon search fieldsGlossary-specific search fields

Common search fields

Glossary-specific search fields

Limiting details

Sorting search results

Paging search results

Aggregating search results

EventsEventsEvent triggersEvent triggersAsset is createdAsset is updatedAsset is deletedCustom metadata is addedCustom metadata is removedAsset is taggedAsset is untaggedLineage is createdEvent typesEvent typesENTITY_CREATEENTITY_UPDATEENTITY_DELETEBUSINESS_ATTRIBUTE_UPDATECLASSIFICATION_ADDCLASSIFICATION_DELETE

Event triggersEvent triggersAsset is createdAsset is updatedAsset is deletedCustom metadata is addedCustom metadata is removedAsset is taggedAsset is untaggedLineage is created

Asset is created

Asset is updated

Asset is deleted

Custom metadata is added

Custom metadata is removed

Asset is tagged

Asset is untagged

Lineage is created

Event typesEvent typesENTITY_CREATEENTITY_UPDATEENTITY_DELETEBUSINESS_ATTRIBUTE_UPDATECLASSIFICATION_ADDCLASSIFICATION_DELETE

ENTITY_CREATE

ENTITY_UPDATE

ENTITY_DELETE

BUSINESS_ATTRIBUTE_UPDATE

CLASSIFICATION_ADD

CLASSIFICATION_DELETE

SpecificationsSpecificationsData contract specOpenLineage spec

Data contract spec

OpenLineage spec

TypesTypesCoreCoreReferenceableAssetConnectionCatalogTagTagAttachmentAccess controlAccess controlPersonaPurposeAuthPolicyAuthServiceBusinessPolicyBusinessPolicyExceptionBusinessPolicyIncidentBusinessPolicyLogIncidentLineageLineageColumnProcessBIProcessResourcesResourcesLinkFileReadmeReadmeTemplateBadgeWorkflowsWorkflowsWorkflowWorkflowRunTaskStructsStructsActionAuthPolicyConditionAuthPolicyValidityScheduleAwsCloudWatchMetricAwsTagAzureTagBadgeConditionBusinessPolicyRuleByocSsoConfigColumnValueFrequencyMapDbtMetricFilterDbtJobRunGoogleLabelGoogleTagHistogramKafkaTopicConsumptionMCRuleComparisonMCRuleSchedulePopularityInsightsSourceTagAttachmentSourceTagAttachmentValueSourceTagAttributeStarredDetailsEnumerationsEnumerationsAdfActivityStateADLSAccessTierADLSAccountStatusADLSEncryptionTypesADLSLeaseStateADLSLeaseStatusADLSObjectArchiveStatusADLSObjectTypeADLSPerformanceADLSProvisionStateADLSReplicationTypeADLSStorageKindAPIQueryParamTypeEnumatlas_operationAtlasGlossaryCategoryTypeAtlasGlossaryTermTypeAtlasGlossaryTypeAtlasGlossaryTermAssignmentStatusAtlasGlossaryTermRelationshipStatusAuthPolicyCategoryAuthPolicyResourceCategoryAuthPolicyTypecertificate_statusDataGlossaryDataProductCriticalityDataProductSensitivityDataProductStatusDataProductVisibilityDomoCardTypeDynamoDBSecondaryIndexProjectionTypeDynamoDBStatusfile_typeFivetranConnectorStatusFivetranProcessStatusgoogle_datastudio_asset_typeicon_typeincident_severitykafka_topic_cleanup_policykafka_topic_compression_typematillion_job_typeModelCardinalityTypeMongoDBCollectionValidationActionMongoDBCollectionValidationLevelOpenLineageRunStatepowerbi_endorsementquery_username_strategyquick_sight_analysis_statusquick_sight_dataset_field_typequick_sight_dataset_import_modequick_sight_folder_typeSchemaRegistrySchemaCompatibilitySchemaRegistrySchemaTypeSourceCostUnitTypetable_typeWorkflowRunStatusWorkflowRunTypeWorkflowStatusWorkflowTypeAbstractionsAbstractionsBICloudInsightObjectStoreEventStoreDataQualityMetricNoSQLSchemaRegistryGlossaryGlossaryAtlasGlossaryAtlasGlossaryCategoryAtlasGlossaryTermData meshData meshDataDomainDataProductDataContractStakeholderStakeholderTitleRelational databasesRelational databasesDatabaseSchemaTableViewMaterialisedViewColumnQueryTablePartitionCalculationViewBigqueryTagDatabricksUnityCatalogTagSnowflakeDynamicTableSnowflakePipeSnowflakeStreamSnowflakeTagProcedureFunctionSQLQuery organizationQuery organizationNamespaceCollectionFolderCubesCubesCubeCubeDimensionCubeHierarchyCubeFieldAPIsAPIsAPIPathAPISpecAPIObjectAPIQueryAPIFieldAirflowAirflowAirflowDagAirflowTaskAmazonAmazonAmazon DynamoDBAmazon DynamoDBDynamoDBTableDynamoDBSecondaryIndexDynamoDBGlobalSecondaryIndexDynamoDBLocalSecondaryIndexAWS S3AWS S3S3BucketS3ObjectAmazon QuickSightAmazon QuickSightQuickSightAnalysisQuickSightAnalysisVisualQuickSightDashboardQuickSightDashboardVisualQuickSightDatasetQuickSightDatasetFieldQuickSightFolderAnaplanAnaplanAnaplanWorkspaceAnaplanAppAnaplanPageAnaplanModelAnaplanModuleAnaplanListAnaplanSystemDimensionAnaplanDimensionAnaplanLineItemAnaplanViewAnomaloAnomaloAnomaloCheckAppAppApplicationApplicationFieldMicrosoft AzureMicrosoft AzureAzure Data FactoryAzure Data FactoryAdfActivityAdfDataflowAdfDatasetAdfLinkedserviceAdfPipelineAzure Data Lake StorageAzure Data Lake StorageADLSAccountADLSContainerADLSObjectAzure Event HubAzure Event HubAzureEventHubAzureEventHubConsumerGroupAzure Service BusAzure Service BusAzureServiceBusNamespaceAzureServiceBusSchemaAzureServiceBusTopicCosmos DBCosmos DBCosmosMongoDBAccountCosmosMongoDBCollectionCosmosMongoDBDatabaseCogniteCogniteCognite3DModelCogniteAssetCogniteEventCogniteFileCogniteSequenceCogniteTimeseriesCustomCustomCustomEntityDataverseDataverseDataverseEntityDataverseAttributedbtdbtDbtColumnProcessDbtMetricDbtModelDbtModelColumnDbtProcessDbtSourceDbtTagDbtTestDomoDomoDomoCardDomoDashboardDomoDatasetDomoDatasetColumnDocumentDBDocumentDBDocumentDBCollectionDocumentDBDatabaseFivetranFivetranFivetranConnectorGoogleGoogleGoogle Cloud StorageGoogle Cloud StorageGCSBucketGCSObjectGoogle Data StudioGoogle Data StudioDataStudioAssetIBMIBMIBMCognosCognosCognosDashboardCognosDatasourceCognosExplorationCognosFileCognosFolderCognosModuleCognosPackageCognosReportKafkaKafkaKafkaConsumerGroupKafkaTopicLookerLookerLookerDashboardLookerExploreLookerFieldLookerFolderLookerLookLookerModelLookerProjectLookerQueryLookerTileLookerViewMatillionMatillionMatillionComponentMatillionGroupMatillionJobMatillionProjectMetabaseMetabaseMetabaseCollectionMetabaseDashboardMetabaseQuestionMicroStrategyMicroStrategyMicroStrategyAttributeMicroStrategyCubeMicroStrategyDocumentMicroStrategyDossierMicroStrategyFactMicroStrategyMetricMicroStrategyProjectMicroStrategyReportMicroStrategyVisualizationModeModeModeChartModeCollectionModeQueryModeReportModeWorkspaceModelsModelsModelAttributeModelAttributeAssociationModelDataModelModelEntityModelEntityAssociationModelVersionMongoDBMongoDBMongoDBCollectionMongDBDatabaseMonte CarloMonte CarloMCIncidentMCMonitorPower BIPower BIPower BIPowerBIColumnPowerBIDashboardPowerBIDataflowPowerBIDataflowEntityColumnPowerBIDatasetPowerBIDatasourcePowerBIMeasurePowerBIPagePowerBIReportPowerBITablePowerBITilePowerBIWorkspacePresetPresetPresetChartPresetDashboardPresetDatasetPresetWorkspaceQlikQlikQlikAppQlikChartQlikDatasetQlikSheetQlikSpaceQlikStreamRedashRedashRedashDashboardRedashQueryRedashVisualizationSalesforceSalesforceSalesforceDashboardSalesforceFieldSalesforceObjectSalesforceOrganizationSalesforceReportSaaSSigmaSigmaSigmaWorkbookSigmaPageSigmaDataElementSigmaDataElementFieldSigmaDatasetSigmaDatasetColumnSisenseSisenseSisenseDashboardSisenseDatamodelSisenseDatamodelTableSisenseFolderSisenseWidgetSodaSodaSodaCheckSparkSparkSparkJobSupersetSupersetSupersetChartSupersetDashboardSupersetDatasetTableauTableauTableauCalculatedFieldTableauDashboardTableauDatasourceTableauDatasourceFieldTableauFlowTableauMetricTableauProjectTableauSiteTableauWorkbookTableauWorksheetThoughtSpotThoughtSpotThoughtspotAnswerThoughtspotColumnThoughtspotDashletThoughtspotLiveboardThoughtspotTableThoughtspotViewThoughtspotWorksheet

CoreCoreReferenceableAssetConnectionCatalogTagTagAttachmentAccess controlAccess controlPersonaPurposeAuthPolicyAuthServiceBusinessPolicyBusinessPolicyExceptionBusinessPolicyIncidentBusinessPolicyLogIncidentLineageLineageColumnProcessBIProcessResourcesResourcesLinkFileReadmeReadmeTemplateBadgeWorkflowsWorkflowsWorkflowWorkflowRunTaskStructsStructsActionAuthPolicyConditionAuthPolicyValidityScheduleAwsCloudWatchMetricAwsTagAzureTagBadgeConditionBusinessPolicyRuleByocSsoConfigColumnValueFrequencyMapDbtMetricFilterDbtJobRunGoogleLabelGoogleTagHistogramKafkaTopicConsumptionMCRuleComparisonMCRuleSchedulePopularityInsightsSourceTagAttachmentSourceTagAttachmentValueSourceTagAttributeStarredDetailsEnumerationsEnumerationsAdfActivityStateADLSAccessTierADLSAccountStatusADLSEncryptionTypesADLSLeaseStateADLSLeaseStatusADLSObjectArchiveStatusADLSObjectTypeADLSPerformanceADLSProvisionStateADLSReplicationTypeADLSStorageKindAPIQueryParamTypeEnumatlas_operationAtlasGlossaryCategoryTypeAtlasGlossaryTermTypeAtlasGlossaryTypeAtlasGlossaryTermAssignmentStatusAtlasGlossaryTermRelationshipStatusAuthPolicyCategoryAuthPolicyResourceCategoryAuthPolicyTypecertificate_statusDataGlossaryDataProductCriticalityDataProductSensitivityDataProductStatusDataProductVisibilityDomoCardTypeDynamoDBSecondaryIndexProjectionTypeDynamoDBStatusfile_typeFivetranConnectorStatusFivetranProcessStatusgoogle_datastudio_asset_typeicon_typeincident_severitykafka_topic_cleanup_policykafka_topic_compression_typematillion_job_typeModelCardinalityTypeMongoDBCollectionValidationActionMongoDBCollectionValidationLevelOpenLineageRunStatepowerbi_endorsementquery_username_strategyquick_sight_analysis_statusquick_sight_dataset_field_typequick_sight_dataset_import_modequick_sight_folder_typeSchemaRegistrySchemaCompatibilitySchemaRegistrySchemaTypeSourceCostUnitTypetable_typeWorkflowRunStatusWorkflowRunTypeWorkflowStatusWorkflowTypeAbstractionsAbstractionsBICloudInsightObjectStoreEventStoreDataQualityMetricNoSQLSchemaRegistry

Referenceable

Asset

Connection

Catalog

Tag

TagAttachment

Access controlAccess controlPersonaPurposeAuthPolicyAuthService

Persona

Purpose

AuthPolicy

AuthService

BusinessPolicy

BusinessPolicyException

BusinessPolicyIncident

BusinessPolicyLog

Incident

LineageLineageColumnProcessBIProcess

ColumnProcess

BIProcess

ResourcesResourcesLinkFileReadmeReadmeTemplateBadge

Link

File

Readme

ReadmeTemplate

Badge

WorkflowsWorkflowsWorkflowWorkflowRunTask

Workflow

WorkflowRun

Task

StructsStructsActionAuthPolicyConditionAuthPolicyValidityScheduleAwsCloudWatchMetricAwsTagAzureTagBadgeConditionBusinessPolicyRuleByocSsoConfigColumnValueFrequencyMapDbtMetricFilterDbtJobRunGoogleLabelGoogleTagHistogramKafkaTopicConsumptionMCRuleComparisonMCRuleSchedulePopularityInsightsSourceTagAttachmentSourceTagAttachmentValueSourceTagAttributeStarredDetails

Action

AuthPolicyCondition

AuthPolicyValiditySchedule

AwsCloudWatchMetric

AwsTag

AzureTag

BadgeCondition

BusinessPolicyRule

ByocSsoConfig

ColumnValueFrequencyMap

DbtMetricFilter

DbtJobRun

GoogleLabel

GoogleTag

Histogram

KafkaTopicConsumption

MCRuleComparison

MCRuleSchedule

PopularityInsights

SourceTagAttachment

SourceTagAttachmentValue

SourceTagAttribute

StarredDetails

EnumerationsEnumerationsAdfActivityStateADLSAccessTierADLSAccountStatusADLSEncryptionTypesADLSLeaseStateADLSLeaseStatusADLSObjectArchiveStatusADLSObjectTypeADLSPerformanceADLSProvisionStateADLSReplicationTypeADLSStorageKindAPIQueryParamTypeEnumatlas_operationAtlasGlossaryCategoryTypeAtlasGlossaryTermTypeAtlasGlossaryTypeAtlasGlossaryTermAssignmentStatusAtlasGlossaryTermRelationshipStatusAuthPolicyCategoryAuthPolicyResourceCategoryAuthPolicyTypecertificate_statusDataGlossaryDataProductCriticalityDataProductSensitivityDataProductStatusDataProductVisibilityDomoCardTypeDynamoDBSecondaryIndexProjectionTypeDynamoDBStatusfile_typeFivetranConnectorStatusFivetranProcessStatusgoogle_datastudio_asset_typeicon_typeincident_severitykafka_topic_cleanup_policykafka_topic_compression_typematillion_job_typeModelCardinalityTypeMongoDBCollectionValidationActionMongoDBCollectionValidationLevelOpenLineageRunStatepowerbi_endorsementquery_username_strategyquick_sight_analysis_statusquick_sight_dataset_field_typequick_sight_dataset_import_modequick_sight_folder_typeSchemaRegistrySchemaCompatibilitySchemaRegistrySchemaTypeSourceCostUnitTypetable_typeWorkflowRunStatusWorkflowRunTypeWorkflowStatusWorkflowType

AdfActivityState

ADLSAccessTier

ADLSAccountStatus

ADLSEncryptionTypes

ADLSLeaseState

ADLSLeaseStatus

ADLSObjectArchiveStatus

ADLSObjectType

ADLSPerformance

ADLSProvisionState

ADLSReplicationType

ADLSStorageKind

APIQueryParamTypeEnum

atlas_operation

AtlasGlossaryCategoryType

AtlasGlossaryTermType

AtlasGlossaryType

AtlasGlossaryTermAssignmentStatus

AtlasGlossaryTermRelationshipStatus

AuthPolicyCategory

AuthPolicyResourceCategory

AuthPolicyType

certificate_status

DataGlossary

DataProductCriticality

DataProductSensitivity

DataProductStatus

DataProductVisibility

DomoCardType

DynamoDBSecondaryIndexProjectionType

DynamoDBStatus

file_type

FivetranConnectorStatus

FivetranProcessStatus

google_datastudio_asset_type

icon_type

incident_severity

kafka_topic_cleanup_policy

kafka_topic_compression_type

matillion_job_type

ModelCardinalityType

MongoDBCollectionValidationAction

MongoDBCollectionValidationLevel

OpenLineageRunState

powerbi_endorsement

query_username_strategy

quick_sight_analysis_status

quick_sight_dataset_field_type

quick_sight_dataset_import_mode

quick_sight_folder_type

SchemaRegistrySchemaCompatibility

SchemaRegistrySchemaType

SourceCostUnitType

table_type

WorkflowRunStatus

WorkflowRunType

WorkflowStatus

WorkflowType

AbstractionsAbstractionsBICloudInsightObjectStoreEventStoreDataQualityMetricNoSQLSchemaRegistry

BI

Cloud

Insight

ObjectStore

EventStore

DataQuality

Metric

NoSQL

SchemaRegistry

GlossaryGlossaryAtlasGlossaryAtlasGlossaryCategoryAtlasGlossaryTerm

AtlasGlossary

AtlasGlossaryCategory

AtlasGlossaryTerm

Data meshData meshDataDomainDataProductDataContractStakeholderStakeholderTitle

DataDomain

DataProduct

DataContract

Stakeholder

StakeholderTitle

Relational databasesRelational databasesDatabaseSchemaTableViewMaterialisedViewColumnQueryTablePartitionCalculationViewBigqueryTagDatabricksUnityCatalogTagSnowflakeDynamicTableSnowflakePipeSnowflakeStreamSnowflakeTagProcedureFunctionSQL

Database

Schema

Table

View

MaterialisedView

Column

Query

TablePartition

CalculationView

BigqueryTag

DatabricksUnityCatalogTag

SnowflakeDynamicTable

SnowflakePipe

SnowflakeStream

SnowflakeTag

Procedure

Function

SQL

Query organizationQuery organizationNamespaceCollectionFolder

Namespace

Collection

Folder

CubesCubesCubeCubeDimensionCubeHierarchyCubeField

Cube

CubeDimension

CubeHierarchy

CubeField

APIsAPIsAPIPathAPISpecAPIObjectAPIQueryAPIField

APIPath

APISpec

APIObject

APIQuery

APIField

AirflowAirflowAirflowDagAirflowTask

AirflowDag

AirflowTask

AmazonAmazonAmazon DynamoDBAmazon DynamoDBDynamoDBTableDynamoDBSecondaryIndexDynamoDBGlobalSecondaryIndexDynamoDBLocalSecondaryIndexAWS S3AWS S3S3BucketS3ObjectAmazon QuickSightAmazon QuickSightQuickSightAnalysisQuickSightAnalysisVisualQuickSightDashboardQuickSightDashboardVisualQuickSightDatasetQuickSightDatasetFieldQuickSightFolder

Amazon DynamoDBAmazon DynamoDBDynamoDBTableDynamoDBSecondaryIndexDynamoDBGlobalSecondaryIndexDynamoDBLocalSecondaryIndex

DynamoDBTable

DynamoDBSecondaryIndex

DynamoDBGlobalSecondaryIndex

DynamoDBLocalSecondaryIndex

AWS S3AWS S3S3BucketS3Object

S3Bucket

S3Object

Amazon QuickSightAmazon QuickSightQuickSightAnalysisQuickSightAnalysisVisualQuickSightDashboardQuickSightDashboardVisualQuickSightDatasetQuickSightDatasetFieldQuickSightFolder

QuickSightAnalysis

QuickSightAnalysisVisual

QuickSightDashboard

QuickSightDashboardVisual

QuickSightDataset

QuickSightDatasetField

QuickSightFolder

AnaplanAnaplanAnaplanWorkspaceAnaplanAppAnaplanPageAnaplanModelAnaplanModuleAnaplanListAnaplanSystemDimensionAnaplanDimensionAnaplanLineItemAnaplanView

AnaplanWorkspace

AnaplanApp

AnaplanPage

AnaplanModel

AnaplanModule

AnaplanList

AnaplanSystemDimension

AnaplanDimension

AnaplanLineItem

AnaplanView

AnomaloAnomaloAnomaloCheck

AnomaloCheck

AppAppApplicationApplicationField

Application

ApplicationField

Microsoft AzureMicrosoft AzureAzure Data FactoryAzure Data FactoryAdfActivityAdfDataflowAdfDatasetAdfLinkedserviceAdfPipelineAzure Data Lake StorageAzure Data Lake StorageADLSAccountADLSContainerADLSObjectAzure Event HubAzure Event HubAzureEventHubAzureEventHubConsumerGroupAzure Service BusAzure Service BusAzureServiceBusNamespaceAzureServiceBusSchemaAzureServiceBusTopicCosmos DBCosmos DBCosmosMongoDBAccountCosmosMongoDBCollectionCosmosMongoDBDatabase

Azure Data FactoryAzure Data FactoryAdfActivityAdfDataflowAdfDatasetAdfLinkedserviceAdfPipeline

AdfActivity

AdfDataflow

AdfDataset

AdfLinkedservice

AdfPipeline

Azure Data Lake StorageAzure Data Lake StorageADLSAccountADLSContainerADLSObject

ADLSAccount

ADLSContainer

ADLSObject

Azure Event HubAzure Event HubAzureEventHubAzureEventHubConsumerGroup

AzureEventHub

AzureEventHubConsumerGroup

Azure Service BusAzure Service BusAzureServiceBusNamespaceAzureServiceBusSchemaAzureServiceBusTopic

AzureServiceBusNamespace

AzureServiceBusSchema

AzureServiceBusTopic

Cosmos DBCosmos DBCosmosMongoDBAccountCosmosMongoDBCollectionCosmosMongoDBDatabase

CosmosMongoDBAccount

CosmosMongoDBCollection

CosmosMongoDBDatabase

CogniteCogniteCognite3DModelCogniteAssetCogniteEventCogniteFileCogniteSequenceCogniteTimeseries

Cognite3DModel

CogniteAsset

CogniteEvent

CogniteFile

CogniteSequence

CogniteTimeseries

CustomCustomCustomEntity

CustomEntity

DataverseDataverseDataverseEntityDataverseAttribute

DataverseEntity

DataverseAttribute

dbtdbtDbtColumnProcessDbtMetricDbtModelDbtModelColumnDbtProcessDbtSourceDbtTagDbtTest

DbtColumnProcess

DbtMetric

DbtModel

DbtModelColumn

DbtProcess

DbtSource

DbtTag

DbtTest

DomoDomoDomoCardDomoDashboardDomoDatasetDomoDatasetColumn

DomoCard

DomoDashboard

DomoDataset

DomoDatasetColumn

DocumentDBDocumentDBDocumentDBCollectionDocumentDBDatabase

DocumentDBCollection

DocumentDBDatabase

FivetranFivetranFivetranConnector

FivetranConnector

GoogleGoogleGoogle Cloud StorageGoogle Cloud StorageGCSBucketGCSObjectGoogle Data StudioGoogle Data StudioDataStudioAsset

Google Cloud StorageGoogle Cloud StorageGCSBucketGCSObject

GCSBucket

GCSObject

Google Data StudioGoogle Data StudioDataStudioAsset

DataStudioAsset

IBMIBMIBMCognosCognosCognosDashboardCognosDatasourceCognosExplorationCognosFileCognosFolderCognosModuleCognosPackageCognosReport

CognosCognosCognosDashboardCognosDatasourceCognosExplorationCognosFileCognosFolderCognosModuleCognosPackageCognosReport

CognosDashboard

CognosDatasource

CognosExploration

CognosFile

CognosFolder

CognosModule

CognosPackage

CognosReport

KafkaKafkaKafkaConsumerGroupKafkaTopic

KafkaConsumerGroup

KafkaTopic

LookerLookerLookerDashboardLookerExploreLookerFieldLookerFolderLookerLookLookerModelLookerProjectLookerQueryLookerTileLookerView

LookerDashboard

LookerExplore

LookerField

LookerFolder

LookerLook

LookerModel

LookerProject

LookerQuery

LookerTile

LookerView

MatillionMatillionMatillionComponentMatillionGroupMatillionJobMatillionProject

MatillionComponent

MatillionGroup

MatillionJob

MatillionProject

MetabaseMetabaseMetabaseCollectionMetabaseDashboardMetabaseQuestion

MetabaseCollection

MetabaseDashboard

MetabaseQuestion

MicroStrategyMicroStrategyMicroStrategyAttributeMicroStrategyCubeMicroStrategyDocumentMicroStrategyDossierMicroStrategyFactMicroStrategyMetricMicroStrategyProjectMicroStrategyReportMicroStrategyVisualization

MicroStrategyAttribute

MicroStrategyCube

MicroStrategyDocument

MicroStrategyDossier

MicroStrategyFact

MicroStrategyMetric

MicroStrategyProject

MicroStrategyReport

MicroStrategyVisualization

ModeModeModeChartModeCollectionModeQueryModeReportModeWorkspace

ModeChart

ModeCollection

ModeQuery

ModeReport

ModeWorkspace

ModelsModelsModelAttributeModelAttributeAssociationModelDataModelModelEntityModelEntityAssociationModelVersion

ModelAttribute

ModelAttributeAssociation

ModelDataModel

ModelEntity

ModelEntityAssociation

ModelVersion

MongoDBMongoDBMongoDBCollectionMongDBDatabase

MongoDBCollection

MongDBDatabase

Monte CarloMonte CarloMCIncidentMCMonitor

MCIncident

MCMonitor

Power BIPower BIPower BIPowerBIColumnPowerBIDashboardPowerBIDataflowPowerBIDataflowEntityColumnPowerBIDatasetPowerBIDatasourcePowerBIMeasurePowerBIPagePowerBIReportPowerBITablePowerBITilePowerBIWorkspace

PowerBIColumn

PowerBIDashboard

PowerBIDataflow

PowerBIDataflowEntityColumn

PowerBIDataset

PowerBIDatasource

PowerBIMeasure

PowerBIPage

PowerBIReport

PowerBITable

PowerBITile

PowerBIWorkspace

PresetPresetPresetChartPresetDashboardPresetDatasetPresetWorkspace

PresetChart

PresetDashboard

PresetDataset

PresetWorkspace

QlikQlikQlikAppQlikChartQlikDatasetQlikSheetQlikSpaceQlikStream

QlikApp

QlikChart

QlikDataset

QlikSheet

QlikSpace

QlikStream

RedashRedashRedashDashboardRedashQueryRedashVisualization

RedashDashboard

RedashQuery

RedashVisualization

SalesforceSalesforceSalesforceDashboardSalesforceFieldSalesforceObjectSalesforceOrganizationSalesforceReportSaaS

SalesforceDashboard

SalesforceField

SalesforceObject

SalesforceOrganization

SalesforceReport

SaaS

SigmaSigmaSigmaWorkbookSigmaPageSigmaDataElementSigmaDataElementFieldSigmaDatasetSigmaDatasetColumn

SigmaWorkbook

SigmaPage

SigmaDataElement

SigmaDataElementField

SigmaDataset

SigmaDatasetColumn

SisenseSisenseSisenseDashboardSisenseDatamodelSisenseDatamodelTableSisenseFolderSisenseWidget

SisenseDashboard

SisenseDatamodel

SisenseDatamodelTable

SisenseFolder

SisenseWidget

SodaSodaSodaCheck

SodaCheck

SparkSparkSparkJob

SparkJob

SupersetSupersetSupersetChartSupersetDashboardSupersetDataset

SupersetChart

SupersetDashboard

SupersetDataset

TableauTableauTableauCalculatedFieldTableauDashboardTableauDatasourceTableauDatasourceFieldTableauFlowTableauMetricTableauProjectTableauSiteTableauWorkbookTableauWorksheet

TableauCalculatedField

TableauDashboard

TableauDatasource

TableauDatasourceField

TableauFlow

TableauMetric

TableauProject

TableauSite

TableauWorkbook

TableauWorksheet

ThoughtSpotThoughtSpotThoughtspotAnswerThoughtspotColumnThoughtspotDashletThoughtspotLiveboardThoughtspotTableThoughtspotViewThoughtspotWorksheet

ThoughtspotAnswer

ThoughtspotColumn

ThoughtspotDashlet

ThoughtspotLiveboard

ThoughtspotTable

ThoughtspotView

ThoughtspotWorksheet

Endpoints

Retrieve workflowBy IDBy type

By ID

By type

Create workflow credentials

Retrieve all workflow credentials

Update workflow source credentials

Hard-delete an workflow credentials

Update workflow configuration

Retrieve workflow runBy IDBy status and time range

By ID

By status and time range

Retrieve all workflow runsBy their phase:

By their phase:

Stop a running workflow

Delete a workflow



## Retrieve workflowÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)



### By IDÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

0.0.162.3.14.0.0

Retrieve an existing workflow by its ID:

12

WorkflowSearchResultresult=WorkflowSearchRequest// (1).findById(client,"atlan-snowflake-miner-1714638976");// (2)

WorkflowSearchResultresult=WorkflowSearchRequest// (1).findById(client,"atlan-snowflake-miner-1714638976");// (2)

You can search for existing workflows through theWorkflowSearchRequestclass.

WorkflowSearchRequest

You can find workflows by their ID using thefindById()helper method and providing the ID for one of the packages. In this example, we're retrieving a specific Snowflake miner package. Because this operation will retrieve information from Atlan, you mustprovide it anAtlanClientthrough which to connect to the tenant.

findById()

AtlanClient

1234567

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()result=client.workflow.find_by_id(# (1)id="atlan-snowflake-miner-1714638976")

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()result=client.workflow.find_by_id(# (1)id="atlan-snowflake-miner-1714638976")

You can find a workflow by its identifier using thefind_by_id()method
of the workflow client, providing theidfor the specific workflow.
In this example, we're retrieving theSnowflakeMinerworkflow.

find_by_id()

id

SnowflakeMiner

12

valresult=WorkflowSearchRequest// (1).findById(client,"atlan-snowflake-miner-1714638976")// (2)

valresult=WorkflowSearchRequest// (1).findById(client,"atlan-snowflake-miner-1714638976")// (2)

You can search for existing workflows through theWorkflowSearchRequestclass.

WorkflowSearchRequest

You can find workflows by their ID using thefindById()helper method and providing the ID for one of the packages. In this example, we're retrieving a specific Snowflake miner package. Because this operation will retrieve information from Atlan, you mustprovide it anAtlanClientthrough which to connect to the tenant.

findById()

AtlanClient

1234

result,atlanErr:=ctx.WorkflowClient.FindByID("atlan-snowflake-miner-1714638976")// (1)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

result,atlanErr:=ctx.WorkflowClient.FindByID("atlan-snowflake-miner-1714638976")// (1)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

You can find a workflow by its identifier using theFindByID()method
of the workflow client, providing theidfor the specific workflow.
In this example, we're retrieving theSnowflakeMinerworkflow.

FindByID()

id

SnowflakeMiner

12345678910111213141516171819202122232425262728293031323334353637383940

{"from":0,"size":1,"track_total_hits":true,"query":{"bool":{"filter":[{"nested":{"path":"metadata","query":{"bool":{"must":[{"term":{"metadata.name.keyword":{"value":"atlan-snowflake-miner-1714638976"// (1)}}}]}}}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

{"from":0,"size":1,"track_total_hits":true,"query":{"bool":{"filter":[{"nested":{"path":"metadata","query":{"bool":{"must":[{"term":{"metadata.name.keyword":{"value":"atlan-snowflake-miner-1714638976"// (1)}}}]}}}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

You can find a workflow by its identifier. In this example, we're retrieving theSnowflakeMinerworkflow.

SnowflakeMiner



### By typeÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

0.0.161.9.54.0.0

Retrieve existing workflows by its type:

12

List<WorkflowSearchResult>results=WorkflowSearchRequest// (1).findByType(client,SnowflakeMiner.PREFIX,5);// (2)

List<WorkflowSearchResult>results=WorkflowSearchRequest// (1).findByType(client,SnowflakeMiner.PREFIX,5);// (2)

You can search for existing workflows through theWorkflowSearchRequestclass.

WorkflowSearchRequest

You can find workflows by their type using thefindByType()helper method and providing the prefix for one of the packages. In this example, we do so for theSnowflakeMiner. (You can also specify the maximum number of resulting workflows you want to retrieve as results.) Because this operation will retrieve information from Atlan, you mustprovide it anAtlanClientthrough which to connect to the tenant.

findByType()

SnowflakeMiner

AtlanClient

12345678

frompyatlan.client.atlanimportAtlanClientfrompyatlan.model.enumsimportWorkflowPackageclient=AtlanClient()results=client.workflow.find_by_type(# (1)prefix=WorkflowPackage.SNOWFLAKE_MINER,max_results=5)

frompyatlan.client.atlanimportAtlanClientfrompyatlan.model.enumsimportWorkflowPackageclient=AtlanClient()results=client.workflow.find_by_type(# (1)prefix=WorkflowPackage.SNOWFLAKE_MINER,max_results=5)

You can find workflows by their type using the workflow clientfind_by_type()method and providing theprefixfor one of the packages.
In this example, we do so for theSnowflakeMiner.
(You can also specify themaximum number of resulting
workflowsyou want to retrieve as results.)

find_by_type()

SnowflakeMiner

12

varresults=WorkflowSearchRequest// (1).findByType(client,SnowflakeMiner.PREFIX,5);// (2)

varresults=WorkflowSearchRequest// (1).findByType(client,SnowflakeMiner.PREFIX,5);// (2)

You can search for existing workflows through theWorkflowSearchRequestclass.

WorkflowSearchRequest

You can find workflows by their type using thefindByType()helper method and providing the prefix for one of the packages. In this example, we do so for theSnowflakeMiner. (You can also specify the maximum number of resulting workflows you want to retrieve as results.) Because this operation will retrieve information from Atlan, you mustprovide it anAtlanClientthrough which to connect to the tenant.

findByType()

SnowflakeMiner

AtlanClient

1234

result,atlanErr:=ctx.WorkflowClient.FindByType(atlan.WorkflowPackageSnowflakeMiner,5)// (1)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

result,atlanErr:=ctx.WorkflowClient.FindByType(atlan.WorkflowPackageSnowflakeMiner,5)// (1)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

You can find workflows by their type using the workflow clientFindByType()method and providing theprefixfor one of the packages.
In this example, we do so for theSnowflakeMiner.
(You can also specify themaximum number of resulting
workflowsyou want to retrieve as results.)

FindByType()

SnowflakeMiner

123456789101112131415161718192021222324252627282930313233

{"from":0,"size":5,// (1)"track_total_hits":true,"query":{"bool":{"filter":[{"nested":{"path":"metadata","query":{"regexp":{"metadata.name.keyword":{"value":"atlan[-]snowflake[-]miner[-][0-9]{10}"}// (2)}}}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

{"from":0,"size":5,// (1)"track_total_hits":true,"query":{"bool":{"filter":[{"nested":{"path":"metadata","query":{"regexp":{"metadata.name.keyword":{"value":"atlan[-]snowflake[-]miner[-][0-9]{10}"}// (2)}}}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

Specify the maximum number of resulting workflows you want to retrieve as results.

In this example, we do so for theSnowflakeMinerwithregexp: atlan[-]snowflake[-]miner[-][0-9]{10}.

SnowflakeMiner

regexp: atlan[-]snowflake[-]miner[-][0-9]{10}



## Create workflow credentialsÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

4.2.1

To create workflow credentials for example, forSnowflake:

Coming soon

12345678910111213141516171819202122

frompyatlan.client.atlanimportAtlanClientfrompyatlan.model.credentialimportCredentialclient=AtlanClient()snowflake_credential=Credential()# (1)snowflake_credential.name="snowflake-credential"# (2)snowflake_credential.connector_config_name="atlan-connectors-snowflake"# (3)snowflake_credential.connector="snowflake"# (4)snowflake_credential.auth_type="basic"# (5)snowflake_credential.username="username"# (6)snowflake_credential.password="password"snowflake_credential.extras={"role":"role-here","warehouse":"warehouse-here",}snowflake_credential.host="test-host"# (7)snowflake_credential.port=1234response=client.credentials.creator(credential=snowflake_credential,test=True# (8))

frompyatlan.client.atlanimportAtlanClientfrompyatlan.model.credentialimportCredentialclient=AtlanClient()snowflake_credential=Credential()# (1)snowflake_credential.name="snowflake-credential"# (2)snowflake_credential.connector_config_name="atlan-connectors-snowflake"# (3)snowflake_credential.connector="snowflake"# (4)snowflake_credential.auth_type="basic"# (5)snowflake_credential.username="username"# (6)snowflake_credential.password="password"snowflake_credential.extras={"role":"role-here","warehouse":"warehouse-here",}snowflake_credential.host="test-host"# (7)snowflake_credential.port=1234response=client.credentials.creator(credential=snowflake_credential,test=True# (8))

Initialize the credential object for credential creation.

You must provide anamefor the credential being created.

name

You must specify theconnector_config_namefor the credential.

connector_config_name

You must specify theconnector namefor the credential.

connector name

You must specify theauthentication typeof the credential.

authentication type

You can provide the sensitive details such as theusername,password, andextraswhen creating credentials. This behavior aligns with the Atlan workflow config.

username

password

extras

You can specify thehostandportbeing used.

host

port

To create workflow credentials using thecreator()method. You need to provide the below params:credential: thecredentialobject is passed to create new credentials in Atlan. For example, in this case,snowflake_credentialserves as the credential object.test: specify whether to validate the credentials (True) or skip validation (False) before creations. Defaults toTrue

To create workflow credentials using thecreator()method. You need to provide the below params:

creator()

credential: thecredentialobject is passed to create new credentials in Atlan. For example, in this case,snowflake_credentialserves as the credential object.

credential

credential

snowflake_credential

test: specify whether to validate the credentials (True) or skip validation (False) before creations. Defaults toTrue

test

True

False

True

Coming soon

1234567891011121314

{"authType":"basic",// (1)"name":"snowflake-credential",//(2)"connector":"snowflake",// (3)"connectorConfigName":"atlan-connectors-snowflake",// (4)"username":"username",// (5)"password":"password","extra":{"role":"role-here","warehouse":"warehouse-here",},"host":"test-host",// (6)"port":1234,}

{"authType":"basic",// (1)"name":"snowflake-credential",//(2)"connector":"snowflake",// (3)"connectorConfigName":"atlan-connectors-snowflake",// (4)"username":"username",// (5)"password":"password","extra":{"role":"role-here","warehouse":"warehouse-here",},"host":"test-host",// (6)"port":1234,}

You must specify theauthTypefor the credential.

authType

You must provide a Human-readable name for your credential.

You must specify theconnectorfor the credential.

connector

You must specify theconnectorConfigNamefor the credential.

connectorConfigName

You can provide the sensitive details such as theusername,password, andextraswhen creating credentials.

username

password

extras

You can specify thehostandportbeing used.

host

port



## Retrieve all workflow credentialsÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

6.0.3

To retrive all workflow credentials for example, forSnowflake:

Coming soon

12345678910

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()response=client.credentials.get_all(#(1)filter={"connector":"snowflake"},limit=5,offset=1,workflow_name="atlan-bigquery-1735837155",)

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()response=client.credentials.get_all(#(1)filter={"connector":"snowflake"},limit=5,offset=1,workflow_name="atlan-bigquery-1735837155",)

To retrieve workflow credentials using theget_all()method. When run without any parameters, it returns all existing records. You can also use following optional parameters to filter, limit, or paginate through the results:(Optional)filter: filters records based on specific key-value criteria, such as{"connector": "snowflake"}returns credentials for workflows using thesnowflakeconnector.(Optional)limit: restricts the maximum number of records returned in a single call, for example,limit=5retrieves up to5records only.(Optional)offset: skips a specified number of records before starting retrieval, such asoffset=10to skip the first10records and retrieve from the11thonward.(Optional)workflow_name: retrieves credentials for a specific workflow. The name should match the workflow name as shown in the Atlan UI.

To retrieve workflow credentials using theget_all()method. When run without any parameters, it returns all existing records. You can also use following optional parameters to filter, limit, or paginate through the results:

get_all()

(Optional)filter: filters records based on specific key-value criteria, such as{"connector": "snowflake"}returns credentials for workflows using thesnowflakeconnector.

filter

{"connector": "snowflake"}

snowflake

(Optional)limit: restricts the maximum number of records returned in a single call, for example,limit=5retrieves up to5records only.

limit

limit=5

5

(Optional)offset: skips a specified number of records before starting retrieval, such asoffset=10to skip the first10records and retrieve from the11thonward.

offset

offset=10

10

11th

(Optional)workflow_name: retrieves credentials for a specific workflow. The name should match the workflow name as shown in the Atlan UI.

workflow_name

Coming soon

1

//(1)

//(1)

All details are in the URL itself.URL-encoded filterNote that the filter is URL-encoded. Decoded it would be:{"name":"atlan-snowflake-17891"}

All details are in the URL itself.

URL-encoded filter

Note that the filter is URL-encoded. Decoded it would be:{"name":"atlan-snowflake-17891"}

{"name":"atlan-snowflake-17891"}



## Update workflow source credentialsÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

1.8.44.0.0

To update workflow source credentials for example, forSnowflake:

1234567891011

CredentialsnowflakeCredential=client.credentials.get(// (1)"972a87c1-28d7-8bf2-896d-ea5bd3e9c691").toCredential().authType("basic")// (2).username("username")// (3).password("password").extra("role","role-here").extra("warehouse","warehouse-here").build()// (4)CredentialResponseresponse=snowflakeCredential.update(client)// (5)

CredentialsnowflakeCredential=client.credentials.get(// (1)"972a87c1-28d7-8bf2-896d-ea5bd3e9c691").toCredential().authType("basic")// (2).username("username")// (3).password("password").extra("role","role-here").extra("warehouse","warehouse-here").build()// (4)CredentialResponseresponse=snowflakeCredential.update(client)// (5)

You can retrieve the workflow credential object by providing itsGUID.

GUID

You must specify the authentication type of the credential.

You must provide the sensitive details such as theusername,password, andextrawhen updating credentials. This behavior aligns with the Atlan workflow config update UI.

username

password

extra

Build the minimalCredentialobject.

Credential

Now, use theupdate()method of theCredentialobject to update this new credentials in Atlan after initially testing it for successful validation. Because this operation will update details in Atlan, you mustprovide it anAtlanClientthrough which to connect to the tenant.

update()

Credential

AtlanClient

1234567891011121314151617181920

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()snowflake_credential=client.credentials.get(guid="972a87c1-28d7-8bf2-896d-ea5bd3e9c691").to_credential()# (1)# Basic Authenticationsnowflake_credential.auth_type="basic"# (2)snowflake_credential.username="username"# (3)snowflake_credential.password="password"snowflake_credential.extras={"role":"role-here","warehouse":"warehouse-here",}response=client.credentials.test_and_update(# (4)credential=snowflake_credential)

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()snowflake_credential=client.credentials.get(guid="972a87c1-28d7-8bf2-896d-ea5bd3e9c691").to_credential()# (1)# Basic Authenticationsnowflake_credential.auth_type="basic"# (2)snowflake_credential.username="username"# (3)snowflake_credential.password="password"snowflake_credential.extras={"role":"role-here","warehouse":"warehouse-here",}response=client.credentials.test_and_update(# (4)credential=snowflake_credential)

You can retrieve the workflow credential object by providing itsGUID.

GUID

You must specify the authentication type of the credential.

You must provide the sensitive details such as theusername,password, andextraswhen updating credentials.
This behavior aligns with the Atlan workflow config update UI.

username

password

extras

Now, pass thecredentialobject to thetest_and_update()method to update this new credentials in Atlan after
initially testing it to confirm its successful validation.

credential

test_and_update()

1234567891011

valsnowflakeCredential=client.credentials.get(// (1)"972a87c1-28d7-8bf2-896d-ea5bd3e9c691").toCredential().authType("basic")// (2).username("username")// (3).password("password").extra("role","role-here").extra("warehouse","warehouse-here").build()// (4)valresponse=snowflakeCredential.update()// (5)

valsnowflakeCredential=client.credentials.get(// (1)"972a87c1-28d7-8bf2-896d-ea5bd3e9c691").toCredential().authType("basic")// (2).username("username")// (3).password("password").extra("role","role-here").extra("warehouse","warehouse-here").build()// (4)valresponse=snowflakeCredential.update()// (5)

You can retrieve the workflow credential object by providing itsGUID.

GUID

You must specify the authentication type of the credential.

You must provide the sensitive details such as theusername,password, andextrawhen updating credentials. This behavior aligns with the Atlan workflow config update UI.

username

password

extra

Build the minimalCredentialobject.

Credential

Now, use theupdate()method of theCredentialobject to update this new credentials in Atlan after initially testing it for successful validation. Because this operation will update details in Atlan, you mustprovide it anAtlanClientthrough which to connect to the tenant.

update()

Credential

AtlanClient

1

// (1)

// (1)

You can retrieve the workflow credential object by providing itsGUID.

GUID

1

// (1)

// (1)

You can also test the existing credential authentication by providing itsGUID.

GUID

1234567891011121314

{"name":"default-snowflake-1735595539-0",// (1)"host":"test.snowflake.com","port":443,"authType":"basic","connectorType":"jdbc","username":"test-username",// (2)"password":"test-password","extra":{"role":"test-role","warehouse":"test-warehouse",},"connectorConfigName":"atlan-connectors-snowflake"}

{"name":"default-snowflake-1735595539-0",// (1)"host":"test.snowflake.com","port":443,"authType":"basic","connectorType":"jdbc","username":"test-username",// (2)"password":"test-password","extra":{"role":"test-role","warehouse":"test-warehouse",},"connectorConfigName":"atlan-connectors-snowflake"}

This example demonstrates how to test & update the source
credentials for theSnowflakecrawler (basic authentication).

This example demonstrates how to test & update the source
credentials for theSnowflakecrawler (basic authentication).

Snowflake

You can update the following credentials fields:username: update with the new username.password: update with the new password.role: update with the new role.warehouse: update with the new warehouse.

You can update the following credentials fields:

username: update with the new username.

username

password: update with the new password.

password

role: update with the new role.

role

warehouse: update with the new warehouse.

warehouse



## Hard-delete an workflow credentialsÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

4.2.0

Hard-deletes (also called a purge) are irreversible operations. The workflow credential is removed from Atlan entirely, so no longer appears in the UI and also no longer exists in Atlan's back-end.

To hard-delete (purge) an asset, you only need to provide the GUID forSnowflake:

Coming soon

12345

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()response=client.credentials.purge_by_guid(guid="972a87c1-28d7-8bf2-896d-ea5bd3e9c691")#(1)

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()response=client.credentials.purge_by_guid(guid="972a87c1-28d7-8bf2-896d-ea5bd3e9c691")#(1)

The credentials.purge_by_guid() method returnsNonewhen the credentials deleted sucessfully.

None

Coming soon

1

//(1)

//(1)

Specify the GUID of the credential to be deleted:api/service/credentials/{credential-guid}/archive

api/service/credentials/{credential-guid}/archive



## Update workflow configurationÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

0.0.162.3.1

To update workflow configuration for example, forSnowflake:

Coming soon

12345678910111213141516

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()result=client.workflow.find_by_id(# (1)id="atlan-snowflake-1714638976")workflow_task=result.source.spec.templates[0].dag.tasks[0]workflow_params=workflow_task.arguments.parameters# (2)foroptioninworkflow_params:ifoption.name=="enable-lineage":# (3)option.value=Trueresponse=client.workflow.update(workflow=result.to_workflow())# (4)

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()result=client.workflow.find_by_id(# (1)id="atlan-snowflake-1714638976")workflow_task=result.source.spec.templates[0].dag.tasks[0]workflow_params=workflow_task.arguments.parameters# (2)foroptioninworkflow_params:ifoption.name=="enable-lineage":# (3)option.value=Trueresponse=client.workflow.update(workflow=result.to_workflow())# (4)

You can find a workflow by its identifier using thefind_by_id()method
of the workflow client, providing theidfor the specific workflow.
In this example, we're retrieving theSnowflakeworkflow for an update.

find_by_id()

id

Snowflake

Retrieve the workflow template and specific task that you need to update.

Update the specific workflow parameter. In this example,
we're enabling lineage for theSnowflakeworkflow.

Snowflake

Convert the workflow search result object to a workflow object
and pass that to theupdate()method to actually perform the workflow update in Atlan.

update()

Coming soon

123456789101112131415

result,_:=ctx.WorkflowClient.FindByID("atlan-snowflake-1714638976")// (1)workflowTask:=result.Source.Spec.Templates[0].DAG.Tasks[0]// (2)workflowParams:=workflowTask.Arguments.Parametersfor_,option:=rangeworkflowParams{ifoption.Name=="enable-lineage"{// (3)option.Value=true}}response,atlanErr:=ctx.WorkflowClient.Update(result.ToWorkflow())// (4)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

result,_:=ctx.WorkflowClient.FindByID("atlan-snowflake-1714638976")// (1)workflowTask:=result.Source.Spec.Templates[0].DAG.Tasks[0]// (2)workflowParams:=workflowTask.Arguments.Parametersfor_,option:=rangeworkflowParams{ifoption.Name=="enable-lineage"{// (3)option.Value=true}}response,atlanErr:=ctx.WorkflowClient.Update(result.ToWorkflow())// (4)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

You can find a workflow by its identifier using theFindByID()method
of the workflow client, providing theidfor the specific workflow.
In this example, we're retrieving theSnowflakeworkflow for an update.

FindByID()

id

Snowflake

Retrieve the workflow template and specific task that you need to update.

Update the specific workflow parameter. In this example,
we're enabling lineage for theSnowflakeworkflow.

Snowflake

Convert the workflow search result object to a workflow object
and pass that to theUpdate()method to actually perform the workflow update in Atlan.

Update()



## Retrieve workflow runÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)



### By IDÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

0.0.162.4.2

Retrieve an existing workflow run by its ID:

Coming soon

1234567

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()result=client.workflow.find_run_by_id(# (1)id="atlan-snowflake-miner-1714638976-mzdza")

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()result=client.workflow.find_run_by_id(# (1)id="atlan-snowflake-miner-1714638976-mzdza")

You can find a workflow run by its identifier using thefind_run_by_id()method
of the workflow client, providing theidfor the specific workflow run.
In this example, we're retrieving the existingSnowflakeMinerworkflow run.

find_run_by_id()

id

SnowflakeMiner

Coming soon

1234

result,atlanErr:=ctx.WorkflowClient.FindRunByID("atlan-snowflake-miner-1714638976-mzdza")// (1)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

result,atlanErr:=ctx.WorkflowClient.FindRunByID("atlan-snowflake-miner-1714638976-mzdza")// (1)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

You can find a workflow run by its identifier using theFindRunByID()method
of the workflow client, providing theidfor the specific workflow run.
In this example, we're retrieving the existingSnowflakeMinerworkflow run.

FindRunByID()

id

SnowflakeMiner

12345678910111213141516171819202122232425262728

{"from":0,"size":1,"track_total_hits":true,"query":{"bool":{"filter":[{"term":{"_id":{"value":"atlan-snowflake-miner-1714638976-mzdza"}// (1)}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

{"from":0,"size":1,"track_total_hits":true,"query":{"bool":{"filter":[{"term":{"_id":{"value":"atlan-snowflake-miner-1714638976-mzdza"}// (1)}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

You can find a workflow run by its identifier.
In this example, we're retrieving the existingSnowflakeMinerworkflow run.

SnowflakeMiner



### By status and time rangeÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

6.1.0

Retrieve existing workflow runs by their status and time range:

Coming soon

1234567891011121314

frompyatlan.client.atlanimportAtlanClientfrompyatlan.model.enumsimportAtlanWorkflowPhaseclient=AtlanClient()results=client.workflow.find_runs_by_status_and_time_range(# (1)status=[AtlanWorkflowPhase.SUCCESS,AtlanWorkflowPhase.FAILED],started_at="now-6h",finished_at="now-1h",from_=0,size=100,)forresultinresults:# (2)# Do something with the workflow...

frompyatlan.client.atlanimportAtlanClientfrompyatlan.model.enumsimportAtlanWorkflowPhaseclient=AtlanClient()results=client.workflow.find_runs_by_status_and_time_range(# (1)status=[AtlanWorkflowPhase.SUCCESS,AtlanWorkflowPhase.FAILED],started_at="now-6h",finished_at="now-1h",from_=0,size=100,)forresultinresults:# (2)# Do something with the workflow...

To search for workflow runs based on their status and time range, use thefind_runs_by_status_and_time_range()method with the following parameters:status(required): filters workflow runs by their status. Acceptable values are defined in theAtlanWorkflowPhaseenum.For example, settingstatus=[AtlanWorkflowPhase.SUCCESS, AtlanWorkflowPhase.FAILED]will retrieve workflow runs that have either asuccessorfailedstatus.started_at(optional): Filters workflow runs based on their start time.For example, settingstarted_at="now-6h"will retrieve runs that started within the last 6 hours.finished_at(optional): Filters workflow runs based on their finish time.For example, settingfinished_at="now-1h"will retrieve runs that finished within the last hour.from_(optional): starting index of the search results (default:0).size(optional): maximum number of search results to return (default:100).Returns a WorkflowSearchResponse object.Not sure about Elasticsearch time range format?Check out theElasticsearch date mathguide for more details.

To search for workflow runs based on their status and time range, use thefind_runs_by_status_and_time_range()method with the following parameters:

find_runs_by_status_and_time_range()

status(required): filters workflow runs by their status. Acceptable values are defined in theAtlanWorkflowPhaseenum.For example, settingstatus=[AtlanWorkflowPhase.SUCCESS, AtlanWorkflowPhase.FAILED]will retrieve workflow runs that have either asuccessorfailedstatus.

status

AtlanWorkflowPhase

status=[AtlanWorkflowPhase.SUCCESS, AtlanWorkflowPhase.FAILED]

success

failed

started_at(optional): Filters workflow runs based on their start time.For example, settingstarted_at="now-6h"will retrieve runs that started within the last 6 hours.

started_at

started_at="now-6h"

finished_at(optional): Filters workflow runs based on their finish time.For example, settingfinished_at="now-1h"will retrieve runs that finished within the last hour.

finished_at

finished_at="now-1h"

from_(optional): starting index of the search results (default:0).

from_

0

size(optional): maximum number of search results to return (default:100).

size

100

Returns a WorkflowSearchResponse object.

Not sure about Elasticsearch time range format?

Check out theElasticsearch date mathguide for more details.

This is the pattern for iterating through all results (across pages) covered in theSearching for assetsportion of the SDK documentation.

This is the pattern for iterating through all results (across pages) covered in theSearching for assetsportion of the SDK documentation.

Coming soon

Coming soon

12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758

{"from":0,// (1)"size":100,// (2)"track_total_hits":true,"query":{"bool":{"must":[{"nested":{"path":"metadata","query":{"terms":{"metadata.labels.workflows.argoproj.io/phase.keyword":[// (3)"Succeeded","Failed"]}}}},{"range":{"status.startedAt":{// (4)"gte":"now-6h"}}},{"range":{"status.finishedAt":{// (5)"gte":"now-1h"}}},{"nested":{"path":"metadata","query":{"exists":{"field":"metadata.labels.workflows.argoproj.io/creator"}}}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

{"from":0,// (1)"size":100,// (2)"track_total_hits":true,"query":{"bool":{"must":[{"nested":{"path":"metadata","query":{"terms":{"metadata.labels.workflows.argoproj.io/phase.keyword":[// (3)"Succeeded","Failed"]}}}},{"range":{"status.startedAt":{// (4)"gte":"now-6h"}}},{"range":{"status.finishedAt":{// (5)"gte":"now-1h"}}},{"nested":{"path":"metadata","query":{"exists":{"field":"metadata.labels.workflows.argoproj.io/creator"}}}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

Starting index of the search results (default:0).

0

Maximum number of search results to return (default:100).

100

You can find workflow runs by their status.
In this example, we're retrieving workflow runs that have either aSucceededorFailedstatus.

Succeeded

Failed

You can use aRangequeryto filter workflow runs based on their start time. 
For example, setting"status.startedAt": {"gte": "now-6h"}will retrieve runs that started within the last 6 hours.

Range

"status.startedAt": {"gte": "now-6h"}

You can use aRangequeryto filter workflow runs based on their finish time.For example, setting"status.finishedAt": {"gte": "now-1h"}will retrieve runs that finished within the last hour.

Range

"status.finishedAt": {"gte": "now-1h"}

Not sure about Elasticsearch time range format?

Check out theElasticsearch date mathguide for more details.



## Retrieve all workflow runsÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

0.0.162.1.8



### By their phase:Â¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

To retrieve all existing workflow runs based on 
their phase, such asSucceeded,Running,Failed, etc

Succeeded

Running

Failed

Coming soon

1234567891011

frompyatlan.client.atlanimportAtlanClientfrompyatlan.model.enumsimportAtlanWorkflowPhaseclient=AtlanClient()response=client.workflow.get_runs(workflow_name="atlan-snowflake-miner-1714638976",workflow_phase=AtlanWorkflowPhase.RUNNING,from_=0,size=100,)# (1)

frompyatlan.client.atlanimportAtlanClientfrompyatlan.model.enumsimportAtlanWorkflowPhaseclient=AtlanClient()response=client.workflow.get_runs(workflow_name="atlan-snowflake-miner-1714638976",workflow_phase=AtlanWorkflowPhase.RUNNING,from_=0,size=100,)# (1)

To retrieve all existing workflow runs
based on their phase, you need to specify:name of the workflow as displayed in the UI, eg:atlan-snowflake-miner-1714638976.phase of the given workflow (e.g:Succeeded,Running,Failed, etc)starting index of the search results (default:0).maximum number of search results to return (default:100).

To retrieve all existing workflow runs
based on their phase, you need to specify:

name of the workflow as displayed in the UI, eg:atlan-snowflake-miner-1714638976.

atlan-snowflake-miner-1714638976

phase of the given workflow (e.g:Succeeded,Running,Failed, etc)

Succeeded

Running

Failed

starting index of the search results (default:0).

0

maximum number of search results to return (default:100).

100

Coming soon

123456789

result,atlanErr:=ctx.WorkflowClient.GetRuns("atlan-snowflake-miner-1714638976",atlan.AtlanWorkflowPhaseSuccess,0,100,)// (1)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

result,atlanErr:=ctx.WorkflowClient.GetRuns("atlan-snowflake-miner-1714638976",atlan.AtlanWorkflowPhaseSuccess,0,100,)// (1)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

To retrieve all existing workflow runs
based on their phase, you need to specify:name of the workflow as displayed in the UI, eg:atlan-snowflake-miner-1714638976.phase of the given workflow (e.g:AtlanWorkflowPhaseSuccess,AtlanWorkflowPhaseRunning,AtlanWorkflowPhaseFailed, etc)starting index of the search results (default:0).maximum number of search results to return (default:100).

To retrieve all existing workflow runs
based on their phase, you need to specify:

name of the workflow as displayed in the UI, eg:atlan-snowflake-miner-1714638976.

atlan-snowflake-miner-1714638976

phase of the given workflow (e.g:AtlanWorkflowPhaseSuccess,AtlanWorkflowPhaseRunning,AtlanWorkflowPhaseFailed, etc)

AtlanWorkflowPhaseSuccess

AtlanWorkflowPhaseRunning

AtlanWorkflowPhaseFailed

starting index of the search results (default:0).

0

maximum number of search results to return (default:100).

100

123456789101112131415161718192021222324252627282930313233343536373839404142

{"from":0,// (1)"size":100,// (2)"track_total_hits":true,"query":{"bool":{"must":[{"nested":{"path":"spec","query":{"term":{"spec.workflowTemplateRef.name.keyword":{"value":"atlan-snowflake-miner-1714638976"}// (3)}}}}],"filter":[{"term":{"status.phase.keyword":{"value":"Succeeded"}// (4)}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

{"from":0,// (1)"size":100,// (2)"track_total_hits":true,"query":{"bool":{"must":[{"nested":{"path":"spec","query":{"term":{"spec.workflowTemplateRef.name.keyword":{"value":"atlan-snowflake-miner-1714638976"}// (3)}}}}],"filter":[{"term":{"status.phase.keyword":{"value":"Succeeded"}// (4)}}]}},"sort":[{"metadata.creationTimestamp":{"order":"desc","nested":{"path":"metadata"}}}]}

Starting index of the search results (default:0).

0

Maximum number of search results to return (default:100).

100

Name of the workflow as displayed in the UI, eg:atlan-snowflake-miner-1714638976.

atlan-snowflake-miner-1714638976

Phase of the given workflow (e.g:Succeeded,Running,Failed, etc)

Succeeded

Running

Failed



## Stop a running workflowÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

0.0.162.1.8

To stop a running workflow:

Coming soon

123456789101112

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()runs=client.workflow.get_runs(workflow_name="atlan-snowflake-miner-1714638976",workflow_phase=AtlanWorkflowPhase.RUNNING,)# (1)response=client.workflow.stop(workflow_run_id=runs[0].id)# (2)

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()runs=client.workflow.get_runs(workflow_name="atlan-snowflake-miner-1714638976",workflow_phase=AtlanWorkflowPhase.RUNNING,)# (1)response=client.workflow.stop(workflow_run_id=runs[0].id)# (2)

First, retrieve all existing running workflows.

From the list of existing running workflows, provide 
the identifier of the specific workflow run to theclient.workflow.stop()method, e.g:atlan-snowflake-miner-1714638976-9wfxz.

client.workflow.stop()

atlan-snowflake-miner-1714638976-9wfxz

Coming soon

12345678910

runs,_:=ctx.WorkflowClient.GetRuns("atlan-snowflake-miner-1714638976-9wfxz",atlan.AtlanWorkflowPhaseRunning,0,100,)// (1)response,atlanErr:=ctx.WorkflowClient.Stop(runs[0].ID)// (2)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

runs,_:=ctx.WorkflowClient.GetRuns("atlan-snowflake-miner-1714638976-9wfxz",atlan.AtlanWorkflowPhaseRunning,0,100,)// (1)response,atlanErr:=ctx.WorkflowClient.Stop(runs[0].ID)// (2)ifatlanErr!=nil{logger.Log.Errorf("Error : %v",atlanErr)}

First, retrieve all existing running workflows.

From the list of existing running workflows, provide 
the identifier of the specific workflow run to thectx.WorkflowClient.Stop()method, e.g:atlan-snowflake-miner-1714638976-9wfxz.

ctx.WorkflowClient.Stop()

atlan-snowflake-miner-1714638976-9wfxz



## Delete a workflowÂ¶
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

0.0.162.1.84.0.0

To delete a workflow:

123

client.workflows.archive("atlan-snowflake-miner-1714638976");// (1)

client.workflows.archive("atlan-snowflake-miner-1714638976");// (1)

To delete an existing workflow, specify the name of the workflow as displayed in the UI (e.g:atlan-snowflake-miner-1714638976).

atlan-snowflake-miner-1714638976

1234567

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()client.workflow.delete(workflow_name="atlan-snowflake-miner-1714638976")# (1)

frompyatlan.client.atlanimportAtlanClientclient=AtlanClient()client.workflow.delete(workflow_name="atlan-snowflake-miner-1714638976")# (1)

To delete an existing workflow, specify:name of the workflow as displayed in the
UI (e.g:atlan-snowflake-miner-1714638976).

To delete an existing workflow, specify:

name of the workflow as displayed in the
UI (e.g:atlan-snowflake-miner-1714638976).

atlan-snowflake-miner-1714638976

123

client.workflows.archive("atlan-snowflake-miner-1714638976")// (1)

client.workflows.archive("atlan-snowflake-miner-1714638976")// (1)

To delete an existing workflow, specify the name of the workflow as displayed in the UI (e.g:atlan-snowflake-miner-1714638976).

atlan-snowflake-miner-1714638976

1

ctx.WorkflowClient.Delete("atlan-snowflake-miner-1714638976")// (1)

ctx.WorkflowClient.Delete("atlan-snowflake-miner-1714638976")// (1)

To delete an existing workflow, specify:name of the workflow as displayed in the
UI (e.g:atlan-snowflake-miner-1714638976).

To delete an existing workflow, specify:

name of the workflow as displayed in the
UI (e.g:atlan-snowflake-miner-1714638976).

atlan-snowflake-miner-1714638976



#### Cookie consent
(source: https://developer.atlan.com/snippets/workflows/manage/workflows/)

We use cookies to:Anonymously measure page views, andAllow you to give us one-click feedback on any page.We donotcollect or store:Any personally identifiable information.Any information for any (re)marketing purposes.With your consent, you're helping us to make our documentation better ð

Anonymously measure page views, and

Allow you to give us one-click feedback on any page.

Any personally identifiable information.

Any information for any (re)marketing purposes.

Google Analytics
